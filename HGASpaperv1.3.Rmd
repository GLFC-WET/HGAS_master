---
title: "A comparison of mixed model approaches as methods to improve estimation of size-adjusted contaminant concentrations in fish population"
author: 
- \* Emily Smenderovac (corresponding author), Great Lakes Forestry Centre, Natural Resources Canada, emily.smenderovac@nrcan-rncan.gc.ca
- Brian W. Kielstra, Ecometrix, Guelph, Ontario, bkielstra@ecometrix.ca
- Calvin Kluke, Living with Lakes Centre, Laurentian University, calvin.kluke1@gmail.com
- Tom Johnston, Living with Lakes Centre, Laurentian University, Ontario Ministry of Natural Resources and Forestry, tjohnston@laurentian.ca
- Satyendra P. Bhavsar, Ontario Ministry of the Environment and Climate Change, satyendra.bhavsar@ontario.ca
- Rob Mackereth, Centre of Excellence for Sustainable Mining and Exploration, Ontario Ministry of Natural Resources and Forestry, rob.mackereth@ontario.ca
- Stephanie Melles, Department of Chemistry and Biology, Toronto Metropolitan University, stephanie.melles@torontomu.ca 
- Gretchen L. Lescord, Forests Fisheries and Geomatic Sciences, University of Florida, lescord.g@ufl.edu
- Erik J.S. Emilson, Great Lakes Forestry Centre, Natural Resources Canada, erik.emilson@nrcan-rncan.gc.ca
date: "`r Sys.Date()`"
bibliography: [packages.bib, references.bib]
csl: environmental-science-and-technology.csl
output: 
  bookdown::word_document2:
    number_sections: true
    global_numbering: true
---

<!--- add to header for final 

: 
    reference_docx: style.docx
    
--->

<!--- Target journal, ES&T Letters
Cover letter: why they believe the manuscript belongs in ES&T and why their research will interest our readers with an emphasis on the novelty and environmental relevance of the contribution. 
Title: Titles should be clear and concise; they must match between manuscript file and electronic submission.
Author list with affiliations: must match between electronic entry and manuscript file
Abstract: 200 word
Manuscript File: Clean with no highlighting or comments and all changes accepted. Line numbers are not required.
(Highly encouraged) Have a colleague in another field read as test for accessibility.
Tables/Schemes/Figures: Text should be clear and legible, with fonts no smaller than 8 pt.
Figures: must be labeled sequentially and match numbered references in article (manuscript and Supporting Information). Where appropriate, label all subsections by letter.
Supporting Information (if any) must be included in the electronic submission.
Table of Contents Graphic
References: no specific format is required, but it must be sufficient to aid referees in their reviewing duties.

Introduction: 500 - 700 words

length limit 7000 words
short synopsis statement (approximately 20 words),

--->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, dev = c('png', "postscript"))
## Load libraries 
library(readxl)
library(lme4)
## install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(sf)
library(INLA)
library(effects)
library(sjPlot)
library(rstanarm)
library(tidyverse)
library(ggpubr)

## Write out package bibliography
knitr::write_bib(file = 'packages.bib')

# Select colours for consistent plots
cust_cols <- c("black", "turquoise")
names(cust_cols) <- c("5 fish or more", "less than 5 fish")
```

# Abstract

The concentration of bioaccumulative contaminants in fish increase with their size and age. Thus, research and monitoring on these contaminants across ecosystems is made more confounded by size effects. To account for these patterns, size-standardization of contaminant concentrations within fish populations is a common practice. Standardized concentrations are often estimated using within-population regression models (referred to as  sampling event regressions, orSERs, herein). This approach requires higher sample sizes than mixed effect models, which are not as commonly used for this purpose. Herein we compare SERs to three mixed effects modeling approaches; restricted maximum likelihood (REML), Bayesian inference via Markov Chain Monte Carlo (MCMC) and, approximate Bayesian inference with nested Laplace approximation (INLA). We did this for two contaminants: mercury (Hg), a contaminant known to bioaccumulate, and arsenic (As), where the bioaccumulative potential is less understood. The mixed model approaches generated accurate size-standardized concentrations for small populations (e.g., <5 fish) and/or populations which lacked the range of sizes required for SER estimates. INLA was determined to be the best method in most cases, because it was computationally less intensive than other approaches and showed consistent performance in a range of sample-size limitation scenarios. Herein, we have provided example code for prediction using the R-INLA package to enable it’s use and application in fisheries contaminant monitoring and research  


# Key Words
Mercury, Arsenic, Fish, Mixed effects models, contaminant modelling


# Introduction


Older and larger fish tend to have higher concentrations of bioaccumulative contaminants that accumulate faster than can be excreted (e.g., mercury, polychlorinated biphenyls). Contaminant monitoring programs often standardize concentrations of these contaminants to common ages, lengths, or weights across fish populations when making comparisons or dietary recommendations, such as in the Guide for Eating Ontario Fish [@MECPGuideDB2023]. Contaminant standardization is also used to control for fish size differences among study sites in research analyses (e.g., Investigations into drivers of contaminant concentrations due to land use, forest change, and natural variation[@johnston2022;@lescord2020;@kidd2012;@ahonen2018]).


A common approach for standardization of fish contaminant concentrations in both research and monitoring programs is to generate a linear equation between concentration and a body size metric, and use this to estimate concentration at a chosen representative size (e.g., 500 g or 1000 g) for each population [@MECPGuideDB2023; @kidd2012;@lescord2019;@sumner2020;@sonesten2003]. This approach (herein referred to as Sampling Event Regressions (SER)) is applied to a broad range of monitored contaminants that can vary in bioaccumulative potential based on chemical characteristics, location, and fish species [@MECPGuideDB2023]. The limitation of the SER approach is that it requires multiple fish (e.g., 5+ fish/population[@gandhi2015]) across a suitable range of body sizes, which can be cost- or time-restrictive for monitoring or research programs. Smaller sample sizes can lead to poor inferences[@weber2021] and/or exclusion of underrepresented waterbodies or species when using the SER approach [@drouillard2016].


A potential alternative to SER, without the sample size limitations, are mixed effects modelling approaches. These approaches offer the advantage of 'borrowing' from all observations across sites for estimating overall “average” relationships while using deviation in absolute values (random intercepts) or relationships (random slopes) among sites (waterbodies) to generate predictions and confidence intervals for a given waterbody and a given fish size [@bolker2009;@zuur2009a]. This approach can potentially increase accuracy and allow estimation even when sample sizes are low, or when there is an inadequate range of body sizes for estimation with SER. A likely barrier to uptake of these approaches by practitioners, however, is the intimidating array of possible approaches with varied complexity, accuracy, and computational requirements. The most accessible implementation is the restricted maximum likelihood approach (REML), which is relatively easy to implement, but is limited in that it does not account for uncertainty in the random effects[@fong2010], which could reduce model fit and increase uncertainty in estimated concentrations. Relatively user-friendly, accessible statistical packages have been introduced that facilitate the inclusion of confidence intervals around estimates. This included bootstrapped likelihoods generated from REML, or estimation of probability distributions either with a Bayesian Markhov Chain Monte Carlo (MCMC) approach or the "approximate Bayesian" Integrated Laplace approximation (INLA) approach. Briefly, these latter two approaches differ in how they estimate probability distributions with MCMC using randomized resampling of both samples and model parameters[@R-rstanarm], and INLA using the (faster) Laplace approximations of probability distributions for each parameter[@INLA2017a;@gomez-rubio2020]. 


Herein we compare four statistical approaches to determine the most accurate way to perform contaminant concentration standardization by fish body size, particularly under data limited scenarios. More specifically, we compared the commonly applied SER to four mixed effects model approaches that differ in how they estimate posteriors: 1) a REML approach, 2) a REML approach with bootstrapping (REML_boot), 3) a common Bayesian inference approach (MCMC), and 4) an approximate Bayesian inference (INLA). We evaluated these approaches using two inorganic contaminants of concern in fish tissue that differ in bioaccumulative potential: mercury (Hg) and arsenic (As). We hypothesized that mixed model approaches would provide comparable or more accurate predictions of contaminant concentrations relative to SERs, but allow estimation in data-scarce populations (i.e., when sample sizes are low and/or when data is limited across size ranges). Amongst mixed model approaches, we expected Bayesian approaches (i.e., MCMC and INLA) to have higher predictive accuracy than REML approaches because of the inclusion of uncertainty in random effects. We expected the REML_boot model to have improved prediction compared to the REML models for the same reason, though with less improvement than Bayesian approaches as the bootstrapping is a more ‘brute force’ approach to error estimation.



# Materials and Methods

## Data

```{r hg-as-data}

### Units for both contaminants are ug/g wet weight
## Read in the mercury data
hg <- readxl::read_excel("./data/Ontario Inland 3 Species Hg 2008-2020-12-16.xlsx") %>% 
  ## filter data to only fish from lakes, produced by MECP, Walleye, Laketrout and Northern Pike and only ones that are from dorsal filet samples
  filter(SPECIES_NAME %in% c("Lake Trout", "Walleye", "Northern Pike"), 
         PORTION_TYPE_DESC %in% c("SKINLESS, BONELESS FILLET (STANDARD MOE DORSAL FILLET)", 
                     "SKINLESS, BONELESS FILLET PLUG (SKIN-OFF)")) %>% 
  mutate(CONTAMINANT = "Hg", WEIGHT_GRAM_LOG = log(WEIGHT_GRAM), LENGTH_CM_LOG = log(LENGTH_CM), 
         VALUE_LOG = log(VALUE)) %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, VALUE_LOG, LENGTH_CM, LENGTH_CM_LOG, WEIGHT_GRAM, WEIGHT_GRAM_LOG) %>% 
  filter(!is.na(LENGTH_CM_LOG), 
         !is.na(WEIGHT_GRAM_LOG))

## Read in the Arsenic data
As <- read.csv("./data/Fish_As_2021.12.01.csv")%>% 
  ## filter data to only fish from lakes, produced by MECP, Walleye, Laketrout and Northern Pike and only ones that are from dorsal filet samples
  filter(System_Type == "Lake",
         Data_source == "MECP", 
         Taxon %in% c("LT", "WALL", "NP"), 
         PORTION_TYPE_DESC %in% c("SKINLESS, BONELESS FILLET (STANDARD MOE DORSAL FILLET)", 
                     "SKINLESS, BONELESS FILLET PLUG (SKIN-OFF)")) %>% 
  mutate(VALUE = As_ug_ww, LENGTH_CM = TLEN/10, WEIGHT_GRAM = RWT,
         WEIGHT_GRAM_LOG = log(RWT), LENGTH_CM_LOG = log(LENGTH_CM), 
         VALUE_LOG = log(VALUE), WATERBODY_CODE = Waterbody, SPECIES_NAME = ifelse(Taxon=="NP", "Northern Pike", ifelse(Taxon == "WALL", "Walleye", "Lake Trout")), 
         SAMPLE_YEAR = as.factor(as.numeric(sapply(strsplit(Sampling_Date, split = "-"), function(x){x[[1]]}))),
         CONTAMINANT = "As") %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, VALUE_LOG, LENGTH_CM, LENGTH_CM_LOG, WEIGHT_GRAM, WEIGHT_GRAM_LOG) %>%
  filter(!is.na(LENGTH_CM_LOG), 
         !is.na(WEIGHT_GRAM_LOG))

## Set seed to make analysis repeatable
set.seed(434)

all_contaminants <- rbind(hg, As) %>%
  mutate(EVENT = paste(WATERBODY_CODE, SAMPLE_YEAR, sep = "_")) %>%
  ### Add a split for test/train data
  group_by() %>%
  mutate(test_train = !((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100))) %>%
  ## used rbinom to sample the fish in the targeted size range at a probability of 50% that they would be included in the test dataset.
  mutate(test_train = ifelse(!test_train, rbinom(sum(!test_train), 1, 0.5), test_train)) %>%
  mutate(VALUE_LOG_TEST = ifelse(!test_train, VALUE_LOG, NA), 
         VALUE_LOG_TRAIN = ifelse(test_train, VALUE_LOG, NA)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN)))


fish_amounts <- all_contaminants %>% group_by(CONTAMINANT) %>% summarize(total_fish = n())

ranges <- all_contaminants %>% 
  group_by(WATERBODY_CODE, SAMPLE_YEAR) %>% 
  summarize(range_wt_train = str_c(WEIGHT_GRAM[test_train == T], collapse = ", "), 
            range_wt_test = str_c(WEIGHT_GRAM[test_train == F], collapse = ", "),
            N_train = sum(test_train), 
            N_test = sum(!test_train),
            N_fish = n())
```

```{r biases, include=FALSE}
all_contaminants %>% group_by(SPECIES_NAME, CONTAMINANT) %>% summarize(weight.p95= quantile(WEIGHT_GRAM,.90), val.p95 = quantile(VALUE,.90))
```

### Fish contaminant data
We obtained a dataset of total Hg and As concentrations ([Hg] and [As] respectively) in fish muscle data from the Ontario Ministry of Environment, Conservation, and Parks (OMECP)[@ontario2023] and from data collected in Northern Ontario for Arsenic studies [@kluke2022]. Although individual fish sampling protocols varied, muscle tissue sent to OMECP is analyzed using standard methods as part of the Fish Contaminants Monitoring Program (FCMP) [@ontario2023]. More specifically, total [Hg] were measured using cold vapor-flameless atomic absorption spectroscopy (CV-FAAS) following protocol OMECP-HGBIO-WS057 and total [As] was measured using Inductively Coupled Plasma Mass Spectrometry (ICP-MS) following method OMECP-BIOTA-E3461.

We included [Hg] because it is a highly bioaccumulative contaminant of global concern that is routinely monitored in fish and used to inform consumption guidelines[@mecp2023]. Size adjustments of [Hg] concentrations in research of variation across environmental gradients are also common [@lescord2020;@sumner2020;@eagles-smith2016;@eckley2023;@negrazis2022]. We also include [As] as a representative contaminant that has also been size-adjusted in research [@kluke2022;@lescord2020], but is less bioaccumulative in fish, showing mixed or weaker relationships with metrics of body size [@lescord2020;@kluke2022;@lepage2024]. We further limited data to only inland lakes (i.e., excluding the Great Lakes) and to three fish species: *Salvelinus namaycush namaycush* (common Lake Trout, hereafter Lake Trout), *Esox lucius* (Northern Pike), and *Sander vitreus* (Walleye). These species were selected because while they are all predators they represent distinct niches within lakes. These species are also commonly consumed by anglers, so accurate estimation of contaminant concentrations is important for mitigating human health risk. Our final dataset included [Hg] in `r fish_amounts$total_fish[fish_amounts$CONTAMINANT == "Hg"]` fish and [As] in `r fish_amounts$total_fish[fish_amounts$CONTAMINANT == "As"]` fish. The datasets were heavily biased to smaller fish, but had a normal distribution of values, with fish between 400 and 1100 being well represented in the data (Figure S\@ref(fig:response-values)). Generally, most fish in the dataset had contaminant concentrations < 1.3 ug/gram~wet weight~ [Hg] and < 0.4 ug/g~wet weight~ [As] (Figure S\@ref(fig:response-values)). 

### Test and training datasets

To facilitate the comparison of standardization approaches, we randomly sampled the fish contaminant datasets to create test and training datasets. We focused on the ability to predict concentrations for two common weight standardization targets of 500g and 1000g, as these were round numbers well represented in the dataset, and commonly used in research studies[@lescord2020; @sumner2020;@lescord2019]. As such, we randomly sampled and assigned 50% of contaminant data from fish weighing 500g ± 100g and 1000g ± 100g to the test dataset, with the remaining 50% of data in those ranges and all data outside of those weight ranges assigned as a training dataset (Table S\@ref(tab:fish-summary)). 
 
 
## Standardization Approaches


### Sampling event regressions (SER)

For each population of fish representing a unique contaminant-species-waterbody-year combination (i.e., a sampling event), we developed log-log (log-contaminant (in ug/g) by log-weight (in g)) regression models. SERS were limited to cases where there were a minimum of 5 sampled individuals, as used in Kluke et al, 2023[-@kluke2022], and also where the range of fish sizes allowed interpolative prediction (i.e., prediction of test set concentrations for weights inside the range of the training set). Our data filtering may be more lenient when compared to methods used in research, due in part to limited data and efficiency. Each model used the linear equation outlined in Equation \@ref(eq:SER-eq).  


\begin{equation}
log(concentration)_k = \beta_{0k} + \beta_{1k} * log(weight_{ik}) + \epsilon_{ik} (\#eq:SER-eq)
\end{equation}


where *i* is an individual fish for each species-waterbody-year combination event *k*, β~0k~ is the intercept, β~1k~ is the slope, and ϵ~ik~ is the residual error; these models were run on training data until all combinations were exhausted. 


```{r sampling-event-regressions}

#### Perform the Sampling Event regressions approach ####
#' This approach creates a separate linear regression for each 
#' lake - sampling year - species combination


## Create a function for performing a log weight - log contaminant model, taking a subset of the dataset as input. The function outputs resulting data and model statistics including R2's and RMSE.
SER_weight_function <- function(x){
  
  ## grab the weight percentile from the data
  percentile <- ecdf(x$WEIGHT_GRAM_LOG)
  
  ## calculate the regression for the sampling event
  tot.time <- system.time(rel <- lm(VALUE_LOG ~ WEIGHT_GRAM_LOG, data = x %>% filter(!is.na(VALUE_LOG_TRAIN))))
  
  ## grab some context and regression summary statistics
  n <- unique(x$N_fish) # number of individuals
  int <- formatC(rel$coefficients[1], digits = 4, format = "f") # estimated intercept
  slp <- formatC(rel$coefficients[2], digits = 4, format = "f") # estimated slope
  int_confint <- paste(formatC(confint(rel)[1, ], digits = 4, format = "f"),
                              collapse = " - ") # estimated intercept confidence interval
  slp_confint <- paste(formatC(confint(rel)[2, ], digits = 4, format = "f"),
                              collapse = " - ") # estimated slope confidence interval
  r2 <- formatC(summary(rel)$r.squared, digits = 4, format = "f") # adjusted R2
  
  ## calculate predicted values for the test data
  fits <- predict(rel, newdata = data.frame(WEIGHT_GRAM_LOG = x$WEIGHT_GRAM_LOG))
  
  ## calculate residuals of just train data for RMSE calculation
  RMSE_resid <- fits - x$VALUE_LOG
  RMSE <- sqrt(mean(RMSE_resid[!is.na(x$VALUE_LOG_TRAIN) & !is.na(RMSE_resid)]^2)) ### This will be used (and calculated for other approaches) to show model performance on lakes with different amounts of fishes - This is ALWAYS done with the test data
  
  resids <- resid(rel)
  
  
  ## Modify the predicted standardized weight too 1000 grams
  pred_modify <- c(1000, 500)
        
  target_size_percentile <- percentile(pred_modify)
        
  ## Generated exponentiated prediction interval
  pred <- exp(predict(rel,
                             newdata = data.frame(WEIGHT_GRAM_LOG= log(pred_modify)),
                             interval = "confidence"
        ))
  pred <- formatC(pred, digits = 4, format = "f")
        
        ## Bring context and summary statistics together into list
        frame <- list(n = n, int = int, int_confint = int_confint, slp = slp, slp_confint = slp_confint, r2 = r2, RMSE = RMSE,
                             target_size_percentile = target_size_percentile, pred = data.frame(pred, WEIGHT_GRAM = c(1000, 500)), data = cbind(x, fits = fits), 
                      run.time = tot.time)
  
}

### Create the series of models and exported results
if(!file.exists("out_workspaces/SER_models.RDS")){
SER_mods <- all_contaminants %>%
  # split the dataset by contaminant, species for each waterbody and sampling year
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$EVENT)) %>%
  discard(~ nrow(.x %>% filter(!is.na(VALUE_LOG_TRAIN))) == 0) %>%
  #'discard(~ nrow(.x %>% group_by() %>%
  #'                 mutate(min_weights = min(WEIGHT_GRAM[!is.na(VALUE_LOG_TRAIN)]),
  #'                        max_weights = max(WEIGHT_GRAM[!is.na(VALUE_LOG_TRAIN)]),
  #'                        min_test_wt = min(WEIGHT_GRAM[is.na(VALUE_LOG_TRAIN)]),
  #'                        max_test_wt = max(WEIGHT_GRAM[is.na(VALUE_LOG_TRAIN)])) %>% 
                   ## Need to ensure the weights of the fish used to create the log-weight model span the weights we are going to standardize to
 #'                  filter(!is.na(VALUE_LOG_TRAIN) & (min_weights<min_test_wt & max_weights>max_test_wt))) < 5) %>%
  map(~ .x %>% group_by() %>%
        mutate(min_weights = min(WEIGHT_GRAM[!is.na(VALUE_LOG_TRAIN)]),
                          max_weights = max(WEIGHT_GRAM[!is.na(VALUE_LOG_TRAIN)]),
                          min_test_wt = min(WEIGHT_GRAM[is.na(VALUE_LOG_TRAIN)]),
                          max_test_wt = max(WEIGHT_GRAM[is.na(VALUE_LOG_TRAIN)])) %>%
       # filter((!is.na(VALUE_LOG_TRAIN) & (min_weights<min_test_wt & max_weights>max_test_wt))|is.na(VALUE_LOG_TRAIN)) %>%
        SER_weight_function())
save(SER_mods, file="out_workspaces/SER_models.RDS")
}else{
  load("out_workspaces/SER_models.RDS")
}


## compile the fitted data and input data
Modelled_data <- lapply(SER_mods, function(x){x$data %>% rename(SER_logfit = fits) %>% 
    # back calculate the fitted values to the un-logged values
    mutate(SER_fit = exp(SER_logfit))}) %>% 
  # compile as dataframe
  bind_rows() 

## Calculate accuracy of Contaminant predictions by this method
SER_accuracy_byN <- Modelled_data %>% filter(!is.na(VALUE_LOG_TEST)) %>% 
  mutate(SER_residuals = SER_fit - VALUE)

# pull the model accuracies (Mean squared errors) for the different models
SER_MSE <- lapply(SER_mods, function(x){data.frame(N_fish = x$n, RMSE = x$RMSE, R2 = x$r2, pred.lower = x$pred[1,2], pred.fit = x$pred[1,1], pred.upper = x$pred[1,3])}) %>% bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         WATERBODY_CODE = str_extract(str_extract(set, "[[:alnum:][:space:]_]+$"), "^[[:alnum:][:space:]]+")) %>%
  filter(WATERBODY_CODE %in% SER_accuracy_byN$WATERBODY_CODE) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    filter(keep)

## compile times for the SER models
SER_times <- lapply(SER_mods, function(x){x$run.time["elapsed"]}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = elapsed) %>%
  group_by(SPECIES_NAME, CONTAMINANT) %>%
  summarize(run.time = sum(run.time)) %>%
  mutate(method = "SER")

## Compile predicted sizes for 500g and 1000g fish with confidence intervals
predicted_data <- lapply(SER_mods, function(x){data.frame(N_fish = x$n, pred.lower = x$pred[,2], pred.fit = x$pred[,1], pred.upper = x$pred[,3], WEIGHT_GRAM = x$pred[,4])}) %>%
  bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         WATERBODY_CODE = str_extract(str_extract(set, "[[:alnum:][:space:]_]+$"), "^[[:alnum:][:space:]]+"), 
         SAMPLE_YEAR = str_extract(set, "[[:digit:]]+$"), 
         method = "SER") %>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method)

```


### Mixed effects models (REML, REML_boot, MCMC and INLA)

For each species and contaminant combination, we developed log-log (log-contaminant (μg/g wet weight) by log-weight (g)) linear mixed effects models including all waterbodies and years. We allowed for random variation in the slope and intercept per waterbody, and random variation in the intercept by sampling event (i.e., each unique year and waterbody combination). The general model structure was \@ref(eq:MEM-eq).


\begin{equation}
log(concentration) = \beta_0 + \beta_1 * log(weight_{ijk}) + \upsilon_{0j} + \upsilon_{1j} * log(weight_{ijk}) + \upsilon_{0k} \epsilon_{ijk} (\#eq:MEM-eq)
\end{equation}


where *i* is an individual fish in waterbody *j* during sampling event *k*, β~0~ is the fixed intercept, β~1~ is the fixed slope, u~0j~ is the random intercept for waterbody *j*, u~1j~ is the random slope for waterbody *j*, u~0k~ is the random intercept for sampling event *k*, and ϵ~ijk~ is residual error. This identical model structure was fit in all three mixed effects model approaches described below.


The REML models were fit using the *lme4* v`r packageVersion("lme4")` package *lmer* function with default settings[@R-lme4] and the REML_boot analysis was performed using *lme4*’s *bootMer* function for parametric bootstrapping using 2000 simulations and with the use.u setting set to TRUE to simulate spherical random effects using 4 CPUs. The MCMC models were fit in STAN v`r rstan::stan_version()` through *rstanarm* v`r packageVersion("rstanarm")`. All models were run with 4 chains (and 4 CPUs)[@R-rstanarm] and the priors were the coefficients of an equivalent glmer model. For [Hg], we used the default settings of 2000 iterations per chain and the adapt_delta setting of 0.8. For [As], however, the lower sample sizes required 9000 iterations and an adapt delta setting of 0.99 for model convergence (at the cost of computation time). The INLA models were run in the *R-INLA* package with the "iid2d" model structure to account for covariance of the random effects due to waterbody[@R-INLA]. The median of predicted test values was used as a comparison to measured values, and also calculate root mean squared error (RMSE) for all models.


```{r lmer-mixedmod}
### Perform the REML-mixed model Maximum likelihood approach.

## Make some functions for easier processing

# Function to bootstrap values
LMER_boot_est <- function(.) {
  c(beta=fixef(.), 
    as.data.frame(VarCorr(.))$sdcor[c(1:3,5)])
}

## function to grab summary of bootstrapping results
LMER_boot_est_summary <- function(merBoot){
  
  t <- as.data.frame(merBoot$t)
  
  names(t) <- c("Intercept", "Slope", "WATERBODY_CODE_SAMPLE_YEAR", 
                "WATERBODY_CODE", "WATERBODY_CODE_SLOPE", "RESIDUAL")
  
  est = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.5, na.rm = T)))
  upr = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.975, na.rm = T)))
  lwr = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.025, na.rm = T)))
  
  ret_tab <- as.data.frame(dplyr::bind_rows(est, lwr, upr))
  rownames(ret_tab) <- c("Estimate", "Lower", "Upper")  
  
  return(ret_tab)  
}

## function to grab summary of predicted values
LMER_boot_pred_summary <- function(merBoot) {
  return(
    data.frame(fit = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.5, na.rm=TRUE))),
               lwr = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE))),
               upr = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
    )
  )
}

## Function to create bootstrapped predictions
LMER_boot_initiate <- function(varlist, nclust, envir){
  closeAllConnections()
  clust <- parallel::makeCluster(nclust)
  parallel::clusterEvalQ(clust, library("lme4"))
  parallel::clusterExport(cl = clust, varlist = varlist, envir = envir)
  showConnections()
  clust
}


lmer_bootstrap_prep <- function(x){
  ## Generate prediction for each waterbody
  prediction.data <- x %>% 
    filter(!is.na(VALUE_LOG_TRAIN)) %>% 
    dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
    distinct() %>% mutate(WEIGHT_GRAM_LOG = log(1000)) %>% 
    rbind( x %>% 
             filter(!is.na(VALUE_LOG_TRAIN)) %>% 
             dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
             distinct() %>% mutate(WEIGHT_GRAM_LOG = log(500)) )
  
  return(list(data = x, preddata = prediction.data))
}

## Function to create initial LMER model using a subset of dataframe
lmer_mass_model <- function(x){
  
  lmer.time <- system.time(mod.lmer <- lmer(VALUE_LOG ~ WEIGHT_GRAM_LOG + (WEIGHT_GRAM_LOG|WATERBODY_CODE) + (1|EVENT), data = x$data[!is.na(x$data$VALUE_LOG_TRAIN), ]))
  
  ## Data for fit/accuracy plotting
  data.out <- x$data %>%
    cbind(LMER_logfit = predict(mod.lmer, newdata = x$data, allow.new.levels = TRUE)) %>% 
    mutate(LMER_resid = LMER_logfit - VALUE_LOG,
           LMER_fit = exp(LMER_logfit))
  
  prediction_data <- x$preddata
  ## get the Bootstrap confidence intervals from bootMer
  clust <- LMER_boot_initiate(varlist = "prediction_data", nclust = 10, envir = environment()) 
  LMER_MASS_boot_est <- lme4::bootMer(mod.lmer, LMER_boot_est, 
                                                      nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                      parallel = "snow", 
                                                      cl = clust, 
                                                      ncpus = 4)
  
  ## Get fitted values from bootstrapping
  LMER_MASS_fit_pred <- function(., newdata) {
      predict(., newdata = x$data, allow.new.levels = TRUE)
  }
  
  
  boot.time <- system.time(LMER_MASS_boot_fit <- lme4::bootMer(mod.lmer, LMER_MASS_fit_pred, 
                                                      nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                      parallel = "snow", 
                                                      cl = clust, 
                                                      ncpus = 4))

  
  ## Function for bootstrapped predictions ## specific for each iteration
   LMER_MASS_boot_pred <- function(., newdata) {
      predict(., newdata=x$preddata)
   }
   
   system.time(LMER_MASS_boot_pred_res <- lme4::bootMer(mod.lmer, LMER_MASS_boot_pred, 
                                                           nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                           parallel = "snow", 
                                                           cl = clust, 
                                                           ncpus = 4)) 
   
   results = list(data = data.out, 
                  bootstrapped.fits = LMER_boot_pred_summary(LMER_MASS_boot_fit), 
                  estimates = LMER_boot_est_summary(LMER_MASS_boot_est),
                  predict = cbind(predict(mod.lmer, newdata=x$preddata), x$preddata), 
                  predicted.1000g = cbind(LMER_boot_pred_summary(LMER_MASS_boot_pred_res), x$preddata), 
                  run.time.lmer = lmer.time,
                  run.time.boot.lmer = boot.time)
}

#### Modelling as separate models by Contaminant ####
if(!file.exists("out_workspaces/LMER_models.RDS")){
  ## Produce individual models for each contaminant/species combination
LMER_data <- all_contaminants %>% 
  split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
  map(~ lmer_bootstrap_prep(.x)) %>% 
  map(~ lmer_mass_model(.x))
  ## Cache this dataset, because TAKES FOREVER
  save(LMER_data, file = "out_workspaces/LMER_models.RDS")
} else {
  load("out_workspaces/LMER_models.RDS")
}



LMER_bootstraps_data <- LMER_data %>% 
  map(~ cbind(.x$data, .x$bootstrapped.fits)) %>% 
  bind_rows() %>% 
  mutate(boot_log_resid = fit - VALUE_LOG) %>% 
  rename(boot_log_fit = fit, boot_log_lwr = lwr, boot_log_upr = upr, REML_log_resid = LMER_resid, REML_logfit = LMER_logfit, REML_fit = LMER_fit) %>%
  mutate(boot_resid = exp(boot_log_fit) - VALUE, 
         REML_resid = REML_fit - VALUE)


## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
Boot_LMER_data_by_N <- LMER_bootstraps_data %>% 
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(boot_REML_RMSE = sqrt(mean(boot_resid[!is.na(VALUE_LOG_TEST)]^2)), REML_RMSE=sqrt(mean(REML_log_resid[!is.na(VALUE_LOG_TEST)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) #%>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
   # mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    #filter(keep) 

  models_accuracy_by_N <- Boot_LMER_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, REML_logfit, REML_log_resid, REML_resid, boot_log_fit, boot_log_resid, boot_resid, N_fish) %>%
    pivot_longer(cols = c(REML_logfit, REML_log_resid, REML_resid, boot_log_fit, boot_log_resid, boot_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(SER_accuracy_byN %>% pivot_longer(cols=c(SER_logfit, SER_fit, SER_residuals), names_to = "response", values_to = "predicted_value"))


models_RMSE <- Boot_LMER_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, boot_REML_RMSE, REML_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(boot_REML_RMSE, REML_RMSE), names_to = "response", values_to = "predicted_value")

models_RMSE <- models_RMSE %>% rbind(SER_MSE %>% rename(predicted_value = RMSE) %>% mutate(response = "SER_RMSE"))

## Compile Run Times
LMER_times <- lapply(LMER_data, function(x){data.frame(V1 = c(x$run.time.lmer["elapsed"], x$run.time.boot.lmer["elapsed"]), method = c("REML", "Boot.REML"))}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

### Compare the results of predicted 1000 g fish
predicted_data <- rbind(predicted_data, LMER_data %>% 
  map(~ rbind(cbind(data.frame(.x$predicted.1000g), WEIGHT_GRAM=c(1000, 500), method = "boot_REML"), 
              cbind(data.frame(.x$predicted), WEIGHT_GRAM=c(1000, 500), method = "REML"))) %>% 
  bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(fit), pred.lower = exp(lwr), 
         pred.upper = exp(upr), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


```{r RSTAN-models}
## Set up RSTAN function to run on data subsets

contam.RSTAN <- function(x){
  
  ## Print out the model for troubleshooting purposes
  message(str_c(unique(x %>% select(SPECIES_NAME, CONTAMINANT)), collapse = " "))
  
  ## Add some Lake Data For predictions
  
  pred.data <- x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(1000)) %>% 
    select(WEIGHT_GRAM_LOG, WATERBODY_CODE, EVENT, SPECIES_NAME, CONTAMINANT) %>%
    distinct() %>% rbind(x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 500, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(500)) %>% 
    select(WEIGHT_GRAM_LOG, WATERBODY_CODE, EVENT, SPECIES_NAME, CONTAMINANT) %>%
    distinct())
  
  ## Grab the time it took to run the overall model using system.time ##
  
  ## Provide more iterations for Arsenic datasets that have fewer data points
  if(nrow(x) < 500){
    iterations = 9000; adapt_delta = 0.99
    }else{
    iterations = 2000; adapt_delta = 0.8} ## This is the setting typically used in the rstan package, though the rstanarm default is be default more strict at 0.95
  
  tot.time <- system.time(RSTAN_MASS <- stan_glmer(VALUE_LOG ~WEIGHT_GRAM_LOG+ (WEIGHT_GRAM_LOG|WATERBODY_CODE) + (1|EVENT),
                     data = x[!is.na(x$VALUE_LOG_TRAIN), ], 
                     cores=4, chains = 4, iter = iterations, adapt_delta = adapt_delta)) ## required some playing around with the iterations, default of 2000 was NOT enough for the As datasets, and was overkill for the large Hg datasets.
  
  fitted.data <- rstanarm::posterior_predict(RSTAN_MASS,
                                                        newdata = x[is.na(x$VALUE_LOG_TRAIN),]
)
  fitted.data <- x[is.na(x$VALUE_LOG_TRAIN),] %>% 
    cbind(t(apply(fitted.data, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}))) %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`) %>%
    mutate(resid_log_rstan = VALUE_LOG - RSTAN_posterior_q50, 
           resid_rstan = exp(VALUE_LOG) - exp(RSTAN_posterior_q50))
  ## Get predicted data for 1000g fishes
  
  RSTAN_MASS_predictions <- rstanarm::posterior_predict(RSTAN_MASS,
                                                        newdata = pred.data
)
  RSTAN_MASS_predictions <- pred.data %>% 
    cbind(t(apply(RSTAN_MASS_predictions, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}))) %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`)
  ## Compile model effects ranges
  
  estimates <- as.data.frame(as.matrix(RSTAN_MASS))
  estimates <- apply(estimates, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}) %>% t() %>% as.data.frame() %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`) %>% 
    rownames_to_column("parameter")
  
  ## Compile results
  results = list(data = x[!is.na(x$VALUE_LOG_TRAIN), ] %>% cbind(resid_log_rstan = resid(RSTAN_MASS)), 
                 fits = fitted.data, 
                 estimates = estimates,
                 predicted.1000g = RSTAN_MASS_predictions, 
                 run.time = tot.time)
}



if(!file.exists("out_workspaces/RSTAN_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  RSTAN_data <- all_contaminants %>% 
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
  map(~ contam.RSTAN(.x))
  ## Cache this dataset, because TAKES FOREVER
  save(RSTAN_data, file = "out_workspaces/RSTAN_models.RDS")
} else {
  load("out_workspaces/RSTAN_models.RDS")
}

RSTAN_data_by_N <- RSTAN_data %>% 
  map(~ rbind(.x$data, .x$fits)) %>% 
  bind_rows() %>% 
  rename(MCMC_log_fit = RSTAN_posterior_q50, MCMC_log_lwr = RSTAN_posterior_q2p5, MCMC_log_upr = RSTAN_posterior_q97p5, MCMC_log_resid = resid_log_rstan, MCMC_resid = resid_rstan) %>% 
  ## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(MCMC_RMSE = sqrt(mean(MCMC_log_resid[!is.na(VALUE_LOG_TRAIN)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) #%>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
    #mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    #filter(keep) 

## Get distinct individual residuals compiled and added to other model results

models_accuracy_by_N <- RSTAN_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, MCMC_log_fit, MCMC_log_resid, MCMC_resid, N_fish) %>%
    pivot_longer(cols = c(MCMC_log_fit, MCMC_log_resid, MCMC_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(models_accuracy_by_N)

## Get data from overall model fits compiled and added to other model results

models_RMSE <- RSTAN_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, MCMC_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(MCMC_RMSE), names_to = "response", values_to = "predicted_value") %>% 
  rbind(models_RMSE)

## Compile Run Times
RSTAN_times <- lapply(RSTAN_data, function(x){data.frame(V1 = c(x$run.time["elapsed"]), method = "MCMC")}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

## RSTAN predicted data for 1000 and 500 
predicted_data <- rbind(predicted_data, RSTAN_data %>% 
  map(~ cbind(data.frame(.x$predicted.1000g), method = "MCMC")) %>% 
  bind_rows(.id = "set") %>% 
  mutate(WEIGHT_GRAM = round(exp(WEIGHT_GRAM_LOG),0), 
         SAMPLE_YEAR = str_extract(EVENT, "[[:digit:]]+$"),
         CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(RSTAN_posterior_q50), pred.lower = exp(RSTAN_posterior_q2p5), 
         pred.upper = exp(RSTAN_posterior_q97p5), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


```{r INLA-models}

## ## Set up precision --> standard deviation formula; Bayesian models use precision (tau) where sd = 1/sqrt(tau) 
MySqrt <- function(x) {
  1 / sqrt(x)
}

## Set up INLA function to run on data subsets

contam.INLA <- function(x){
  
  ## Add some Lake Data For predictions
  
  pred.data <- x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(1000)) %>% 
    distinct() %>% rbind(
      x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(500)) %>% 
    distinct()
    )
  
  x <- x %>% rbind(pred.data)
  
  ## Grab the time it took to run the overall model using system.time ##
  
  ## Add dummy variable for the random effects
  
  tot.time <- system.time(INLA_MASS <- inla(VALUE_LOG_TRAIN ~WEIGHT_GRAM_LOG+ 
                      #' The next two lines code for the random slopes effect due to waterbody, - basically codes for the random effect of the 
                      #' two variables, expecting covariance of these variables  
                      #' See the documentation for the description of this implementation 'inla.doc("iid2d")'
                       f(WATERBODY_CODE1, n = 2*unique(x$n_waterbody), model = "iid2d") + 
                       f(WATERBODY_CODE2, WEIGHT_GRAM_LOG, copy = "WATERBODY_CODE1") + 
                       f(EVENT, model = "iid"),
                     data = x, 
                     control.predictor = list(
                       compute = TRUE, 
                       quantiles = c(0.025, 0.5, 0.975)
                     ),
                     control.compute = list(
                       cpo = TRUE
                     )
                    ))
  
  fitted.data <- data.frame(WATERBODY_CODE = x$WATERBODY_CODE,
                       SAMPLE_YEAR = x$SAMPLE_YEAR, 
                       SPECIES_NAME = x$SPECIES_NAME,
                       CONTAMINANT = x$CONTAMINANT, 
                       VALUE = x$VALUE, 
                       VALUE_LOG = x$VALUE_LOG,
                       WEIGHT_GRAM = x$WEIGHT_GRAM, 
                       WEIGHT_GRAM_LOG = x$WEIGHT_GRAM_LOG,
                       TEST.val = !is.na(x$VALUE_LOG_TEST), 
                       INLA_posterior_q50 = INLA_MASS$summary.fitted.values[, "0.5quant"], 
                       INLA_posterior_q2p5 = INLA_MASS$summary.fitted.values[, "0.025quant"], 
                       INLA_posterior_q97p5 = INLA_MASS$summary.fitted.values[, "0.975quant"]) %>% 
    mutate(resid_log_inla = VALUE_LOG - INLA_posterior_q50, 
           resid_inla = exp(VALUE_LOG) - exp(INLA_posterior_q50))
  
  ## Compile model effects ranges
  fixed.effect <- INLA_MASS$summary.fixed
  fixed.effect$Type <- "Fixed"
  
  random.effect.lake <- INLA_MASS$summary.random$WATERBODY_CODE1
  random.effect.lake$ID <- as.character(random.effect.lake$ID)
  random.effect.lake$WATERBODY_CODE1 <- random.effect.lake$ID
  random.effect.lake <- merge(random.effect.lake, distinct(x[,c("WATERBODY_CODE1", "WATERBODY_CODE")]), no.dups = T)
  random.effect.lake <- random.effect.lake[!duplicated(random.effect.lake), ]
  random.effect.lake$Type <- "Random Intercept - Waterbody"
  
  random.slope.lake <- INLA_MASS$summary.random$WATERBODY_CODE2
  random.slope.lake$ID <- as.character(random.slope.lake$ID)
  random.slope.lake$WATERBODY_CODE2 <- random.slope.lake$ID
  random.slope.lake <- merge(random.slope.lake, distinct(x[,c("WATERBODY_CODE2", "WATERBODY_CODE")]), no.dups = T)
  random.slope.lake <- random.slope.lake[!duplicated(random.slope.lake), ]
  random.slope.lake$Type <- "Random Slope - Waterbody"
  
  random.effect.event <- INLA_MASS$summary.random$EVENT
  random.effect.event$ID <- as.character(random.effect.event$ID)
  random.effect.event$EVENT <- random.effect.event$ID
  random.effect.event <- random.effect.event[!duplicated(random.effect.event), ]
  random.effect.event$Type <- "Random Slope - Waterbody Sampling Year"
  
  estimates <- list(fixed.effect = fixed.effect, random.effect.lake = random.effect.lake, 
                    random.slope.lake = random.slope.lake, random.effect.event = random.effect.event)
  ## Compile results
  results = list(data = fitted.data[!fitted.data$TEST.val & !is.na(fitted.data$VALUE), ], 
                 fits = fitted.data[fitted.data$TEST.val & !is.na(fitted.data$VALUE), ], 
                 estimates = estimates,
                 predicted.1000g = fitted.data[is.na(fitted.data$VALUE), ], 
                 run.time = tot.time)
}


if(!file.exists("out_workspaces/INLA_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  
  INLA_data <- all_contaminants %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(WATERBODY_CODE1 = as.integer(as.factor(WATERBODY_CODE))) %>% # for inla model, this needs to be an integer
    mutate(WATERBODY_CODE2 = WATERBODY_CODE1 + max(WATERBODY_CODE1)) %>% # for inla model, this needs to be a different set of integers
    mutate(n_waterbody = n_distinct(WATERBODY_CODE)) %>% # for inla model, we need to have a number of lakes assigned for setting the appropriate attributes for a two-dimensional model
    split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
    map(~ contam.INLA(.x))
  ## Cache this dataset, because TAKES FOREVER
    save(INLA_data, file = "out_workspaces/INLA_models.RDS")
} else {
  load("out_workspaces/INLA_models.RDS")
}

## Summarize data by event
INLA_data_by_N <- INLA_data %>% 
  map(~ rbind(.x$data %>% mutate(VALUE_LOG_TRAIN = VALUE_LOG, VALUE_LOG_TEST = NA), .x$fits %>% mutate(VALUE_LOG_TRAIN = NA, VALUE_LOG_TEST = VALUE_LOG))) %>% 
  bind_rows() %>% 
  rename(INLA_log_fit = INLA_posterior_q50, INLA_log_lwr = INLA_posterior_q2p5, INLA_log_upr = INLA_posterior_q97p5, INLA_log_resid = resid_log_inla, INLA_resid = resid_inla) %>% 
  ## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(INLA_RMSE = sqrt(mean(INLA_log_resid[!is.na(VALUE_LOG_TRAIN)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) # %>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
   # mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
   #filter(keep) 

## Get distinct individual residuals compiled and added to other model results

models_accuracy_by_N <- INLA_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, INLA_log_fit, INLA_log_resid, INLA_resid, N_fish) %>%
    pivot_longer(cols = c(INLA_log_fit, INLA_log_resid, INLA_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(models_accuracy_by_N)

## Get data from overall model fits compiled and added to other model results

models_RMSE <- INLA_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, INLA_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(INLA_RMSE), names_to = "response", values_to = "predicted_value") %>% 
  rbind(models_RMSE)

## Compile Run Times
INLA_times <- lapply(INLA_data, function(x){data.frame(V1 = c(x$run.time["elapsed"]), method = "INLA")}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

## INLA predicted data for 1000 and 500 
predicted_data <- rbind(predicted_data, INLA_data %>% 
  map(~ cbind(data.frame(.x$predicted.1000g), method = "INLA")) %>% 
  bind_rows(.id = "set") %>% 
  mutate(WEIGHT_GRAM = round(exp(WEIGHT_GRAM_LOG),0), 
         CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(INLA_posterior_q50), pred.lower = exp(INLA_posterior_q2p5), 
         pred.upper = exp(INLA_posterior_q97p5), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


## Population medians (no standardization)


We calculated the population median of [As] values for each of the three fish species and both contaminants, individually for each waterbody-year combination  (i.e., a sampling event), as it is possible that there is no bioaccumulation of this contaminant in some species. We included this comparison as a predictive approach, as good prediction with median values rather than with standardized concentrations implies that there is a lack of bioaccumulation.


## Comparing model fit and predictive accuracy


To assess the predictive accuracy of each approach, we compared predictions of test set values to the recorded measured values using Pearson correlation with the cor.test function in R. We also assessed the fit of each approach by calculating the root mean squared error (RMSE) of the training set for each sampling event (distinct year-waterbody combination) in the dataset. Accuracies based on test data reflect the generalized predictive capability of a model, while fit reflects the accuracy of the model in representing the trends present in the training data. Additionally, to provide context about the accessibility of the different approaches, we collected and compared the required computational time required to run each model to the RMSE of the overall models. 


We ran an additional analysis to determine if there was a threshold number of fish per sample event that, after which, no additional benefit to the predictive accuracy of the overall model was observed. To do this, we trained REML and INLA models that only allowed sampling events to have fish up to a particular threshold number to compare REML and Bayesian approaches. We used the less computationally intensive INLA approach to represent both Bayesian approaches, as INLA and MCMC were highly similar. This was run for every size between 5 and the maximum number of fish possible for the events in the dataset.  


```{r lmer-models-max-sampsize, include=FALSE}
### Perform the REML-mixed model Maximum likelihood approach for different max-N training sets.

#' We iterate through sizes of training sets where we restrict the training set data so that data are subset to a maximum amount of allowable fish 
#' (i.e., no individual samplng set in the data is allowed to be higher than the set value)

## Make some functions for easier processing

lmer_bootstrap_prep <- function(x){
  ## Generate prediction for each waterbody
  prediction.data <- x %>% 
    filter(!is.na(VALUE_LOG_TRAIN)) %>% 
    dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
    distinct() %>% mutate(WEIGHT_GRAM_LOG = log(1000)) %>% 
    rbind( x %>% 
             filter(!is.na(VALUE_LOG_TRAIN)) %>% 
             dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
             distinct() %>% mutate(WEIGHT_GRAM_LOG = log(500)) )
  
  return(list(data = x, preddata = prediction.data))
}

## Function to create initial LMER model using a subset of dataframe
lmer_mass_model <- function(x){
  
  lmer.time <- system.time(mod.lmer <- lmer(VALUE_LOG ~ WEIGHT_GRAM_LOG + (WEIGHT_GRAM_LOG|WATERBODY_CODE) + (1|EVENT), data = x$data[!is.na(x$data$VALUE_LOG_TRAIN), ]))
  
  ## Data for fit/accuracy plotting
  data.out <- x$data %>%
    cbind(LMER_logfit = predict(mod.lmer, newdata = x$data, allow.new.levels = TRUE)) %>% 
    mutate(LMER_resid = LMER_logfit - VALUE_LOG,
           LMER_fit = exp(LMER_logfit))
 
   results = list(data = data.out)
}


## First we produce the combinations of max #fish and #lakes included in models

sets <- all_contaminants %>% dplyr::select(WATERBODY_CODE, CONTAMINANT, SPECIES_NAME, SAMPLE_YEAR) %>% distinct() %>% arrange(SPECIES_NAME, CONTAMINANT, WATERBODY_CODE, SAMPLE_YEAR) %>% group_by(WATERBODY_CODE, SPECIES_NAME, CONTAMINANT) %>%
  summarize(multi.year = n()>1,
            numyears = n(), 
            years = str_c(SAMPLE_YEAR, collapse = ", "))


Multi.year <- sets %>% group_by(SPECIES_NAME, CONTAMINANT) %>%
  summarize(Multi.year = sum(multi.year),
            one.year = sum(!multi.year), 
            years.range = str_c(unique(unlist(str_extract_all(years, "[[:digit:]]+"))), collapse = ", "))

#### Modelling as separate models by Contaminant ####
if(!file.exists("out_workspaces/LMER_numfish_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  LMER_fish_data <- lapply(5:50, function(fishnum){print(fishnum)
    all_contaminants %>%
    mutate(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>%
    arrange(is.na(VALUE_LOG_TEST)) %>% 
    mutate(N_fish = sum(is.na(VALUE_LOG_TEST)), 
      samp_num = min(fishnum, N_fish)) %>%
    mutate(keep = ifelse(is.na(VALUE_LOG_TEST), 
                         sample(c(rep(T, unique(samp_num)), 
                                  rep(F, unique(N_fish)-unique(samp_num))),
                                  unique(N_fish), replace = F),
                         F))%>%
    group_by() %>% 
    mutate(VALUE_LOG_TRAIN = ifelse(keep, VALUE_LOG, NA)) %>%
      split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
      map(~ lmer_bootstrap_prep(.x)) %>% 
      map(~ lmer_mass_model(.x)) %>%
      map(~ .x$data) %>% 
        bind_rows() %>% 
        filter(is.na(VALUE_LOG_TRAIN)) %>%
        rename(REML_log_resid = LMER_resid, REML_logfit = LMER_logfit, REML_fit = LMER_fit) %>%
      dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, REML_fit, REML_log_resid, REML_logfit) %>%
    pivot_longer(cols = c(REML_fit, REML_log_resid, REML_logfit), names_to = "response", values_to = "predicted_value")  %>%
        mutate(maxfish = fishnum)})
  
  LMER_fish_data <- bind_rows(LMER_fish_data)
  ## Cache this dataset, because TAKES FOREVER
    save(LMER_fish_data, file = "out_workspaces/LMER_numfish_models.RDS")
} else {
  load("out_workspaces/LMER_numfish_models.RDS")
}

```



```{r INLA-models-max-samp-size, include = FALSE}

## ## Set up precision --> standard deviation formula; Bayesian models use precision (tau) where sd = 1/sqrt(tau) 
MySqrt <- function(x) {
  1 / sqrt(x)
}

## Set up INLA function to run on data subsets

contam.INLA.N <- function(x){
  
  # Set prior on precision
  prec.prior <- list(prec = list(param = c(0.001, 0.001)))
  
  ## Add some Lake Data For predictions
  
  x <- x %>%
    mutate(VALUE_TEST = ifelse(!is.na(VALUE_LOG_TEST), VALUE, NA), 
           VALUE_TRAIN = ifelse(!is.na(VALUE_LOG_TRAIN), VALUE, NA))
  
  ## Grab the time it took to run the overall model using system.time ##
  
  ## Add dummy variable for the random effects
  
  tot.time <- system.time(INLA_MASS <- inla(VALUE_LOG_TRAIN ~WEIGHT_GRAM_LOG+ 
                      #' The next two lines code for the random slopes effect due to waterbody, - basically codes for the random effect of the 
                      #' two variables, expecting covariance of these variables  
                      #' See the documentation for the description of this implementation 'inla.doc("iid2d")'
                       f(WATERBODY_CODE1, n = 2*unique(x$n_waterbody), model = "iid2d") + 
                       f(WATERBODY_CODE2, WEIGHT_GRAM_LOG, copy = "WATERBODY_CODE1") + 
                       f(EVENT, model = "iid"),
                     data = x, 
                     control.predictor = list(
                       compute = TRUE, 
                       quantiles = c(0.025, 0.5, 0.975)
                     ),
                     control.compute = list(
                       cpo = TRUE
                     )#, safe =F
                    ))
  
  fitted.data <- data.frame(WATERBODY_CODE = x$WATERBODY_CODE,
                       SAMPLE_YEAR = x$SAMPLE_YEAR, 
                       SPECIES_NAME = x$SPECIES_NAME,
                       CONTAMINANT = x$CONTAMINANT, 
                       VALUE = x$VALUE, 
                       VALUE_LOG = x$VALUE_LOG,
                       WEIGHT_GRAM = x$WEIGHT_GRAM, 
                       WEIGHT_GRAM_LOG = x$WEIGHT_GRAM_LOG,
                       TEST.val = !is.na(x$VALUE_LOG_TEST), 
                       INLA_posterior_q50 = INLA_MASS$summary.fitted.values[, "0.5quant"], 
                       INLA_posterior_q2p5 = INLA_MASS$summary.fitted.values[, "0.025quant"], 
                       INLA_posterior_q97p5 = INLA_MASS$summary.fitted.values[, "0.975quant"]) %>% 
    mutate(resid_log_inla = VALUE_LOG - INLA_posterior_q50, 
           resid_inla = VALUE - exp(INLA_posterior_q50))
  

  ## Compile results
  results = list(data = fitted.data[!fitted.data$TEST.val & !is.na(fitted.data$VALUE), ], 
                 fits = fitted.data[fitted.data$TEST.val & !is.na(fitted.data$VALUE), ])
}


if(!file.exists("out_workspaces/INLA_numfish_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  INLA_fish_data <- lapply(5:50, function(fishnum){print(fishnum)
    all_contaminants %>%
    mutate(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>%
    arrange(is.na(VALUE_LOG_TEST)) %>% 
    mutate(N_fish = sum(is.na(VALUE_LOG_TEST)), 
      samp_num = min(fishnum, N_fish)) %>%
    mutate(keep = ifelse(is.na(VALUE_LOG_TEST), 
                         sample(c(rep(T, unique(samp_num)), 
                                  rep(F, unique(N_fish)-unique(samp_num))),
                                  unique(N_fish), replace = F),
                         F))%>% 
    group_by() %>% 
    mutate(VALUE_LOG_TRAIN = ifelse(keep, VALUE_LOG, NA)) %>%
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(WATERBODY_CODE1 = as.integer(as.factor(WATERBODY_CODE))) %>% # for inla model, this needs to be an integer
    mutate(WATERBODY_CODE2 = WATERBODY_CODE1 + max(WATERBODY_CODE1)) %>% # for inla model, this needs to be a different set of integers
    mutate(n_waterbody = n_distinct(WATERBODY_CODE)) %>% # for inla model, we need to have a number of lakes assigned for setting the appropriate attributes for a two-dimensional model
    split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
    map(~ contam.INLA.N(.x)) %>% 
 map(~ rbind(.x$fits %>% mutate(VALUE_LOG_TRAIN = NA, VALUE_LOG_TEST = log(VALUE)))) %>% 
  bind_rows() %>% 
  rename(INLA_fit = INLA_posterior_q50, INLA_lwr = INLA_posterior_q2p5, INLA_upr = INLA_posterior_q97p5, INLA_log_resid = resid_log_inla, INLA_resid = resid_inla) %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, INLA_fit, INLA_log_resid, INLA_resid) %>%
    pivot_longer(cols = c(INLA_fit, INLA_log_resid, INLA_resid), names_to = "response", values_to = "predicted_value") %>%
    mutate(maxfish = fishnum)})
  
  INLA_fish_data <- bind_rows(INLA_fish_data)
  ## Cache this dataset, because TAKES FOREVER
    save(INLA_fish_data, file = "out_workspaces/INLA_numfish_models.RDS")
} else {
  load("out_workspaces/INLA_numfish_models.RDS")
}

```


Additionally, we collected and compare the required computational time for each approach. Computational times as presented are in the context of analyses performed in `r version$version.string` [@R-base] on a Dell Latitude 5510 PC running Windows 10 Enterprise with a 1.70GHz, 2208 MHz 4 Core(s), 8 logical processor, 16 GB of physical memory and 34.6 GB of virtual memory. All data transformations, summarizations and graphing were performed with the *tidyverse* v`r packageVersion("tidyverse")`, *ggplot2* v`r packageVersion("ggplot2")` and *ggpubr* v`r packageVersion("ggpubr")` packages [@R-tidyverse; @R-ggplot2; @R-ggpubr].


# Results and Discussion


Of all the approaches tested in this paper, REML and INLA were the most practical for producing accurate size-standardized  estimates of contaminant concentration for distinct waterbodies. Both techniques allowed for predictions in waterbodies where SER could not be performed. The predictions were highly comparable to the measured values and had favourable computational speed when compared to other approaches. REML may be more appropriate for many situations, as the implementation was less conceptually complex and more easily programmed at the time of writing this paper. However, INLA performed effectively on all datasets, and had more predictable performance when run on a variety of sample sizes. 


```{r pred-resid-table-fig-Hg, fig.width=8, fig.height=10.5, fig.cap = "Table of [Hg] model prediction results for tissue of 400-600g and 900-1100g fish compared to measured values. The table includes a column of correlation statistics (r and p-value) for each model assessed in the study. To the right of the plot, a dot plot shows the distribution of model residuals for events with less than five fish (grey), or 5 or more fish (black). A central hollow circle designates the median, with a solid error bar designating the 2.5, and 95th percentiles of the distribution. A dashed line ending in a + is used to show the range of remaining residuals. A vertical red line is used to highlight where the distributions overlap with zero. Particularly large outliers or percentiles are indicated in text on the left side of the plot.", message = FALSE}

## Calculate the straight means and include with the rest of the values as a comparison for the Arsenic predictions
mean_mods <- all_contaminants %>%
  # split the dataset by contaminant, species for each waterbody and sampling year
  group_by(CONTAMINANT, SPECIES_NAME, EVENT) %>%
  mutate(mean_logfit = mean(VALUE_LOG_TRAIN, na.rm = T)) %>% 
  mutate(predicted_value = mean_logfit,
         response = "mean_logfit",
         N_fish = sum(is.na(VALUE_LOG_TEST))) %>%
  filter(!is.na(VALUE_LOG_TEST), CONTAMINANT == "As") %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, N_fish, response, predicted_value, LENGTH_CM, LENGTH_CM_LOG, EVENT, test_train, VALUE_LOG_TEST, VALUE_LOG_TRAIN)


## Lm summaries
lm_sums <- models_accuracy_by_N %>% rbind(mean_mods) %>%
         filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit", "mean_logfit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA"))) %>%
  mutate(predicted = exp(predicted_value)) %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$response)) %>%
  discard(~ nrow(.x)==0) %>%
    map(~ list(mod = try(cor.test(.x$predicted,.x$VALUE)))) %>%
    map(~ data.frame(Cor = ifelse(class(.x$mod) != "try-error", round(.x$mod$estimate, 2), NA),
                     p = ifelse(class(.x$mod) != "try-error", round(.x$mod$p.value, 2), NA))) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         response = factor(str_extract(set, "SER|mean|boot_REML|REML|MCMC|INLA_ll|INLA"), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll")),
         R2.text = ifelse(!is.na(Cor), paste0("r = ", Cor, "\np ",ifelse(p < 0.05, "< 0.05", paste0("= ", p))), "Not enough data")) %>% 
  arrange(response, CONTAMINANT, SPECIES_NAME) %>%
  mutate(plotorder =paste(CONTAMINANT, SPECIES_NAME, response), 
         plotorder = factor(plotorder, levels = unique(plotorder))) %>% 
  dplyr::select(plotorder, SPECIES_NAME, CONTAMINANT, response, R2.text) 

## Get Residual statistics for each approach
## filtered out one crazy high residual from Northern Pike SER
Residual.plotting <- models_accuracy_by_N %>% 
                  rbind(mean_mods) %>% 
                  mutate(EVENT = paste0(WATERBODY_CODE, "_", "SAMPLE_YEAR")) %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more")) %>%
         filter(response %in% c("REML_logfit", "mean_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit"))%>%
                  mutate(residual = exp(predicted_value) - VALUE) %>%
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA"))) %>% 
  group_by(SEN, response, SPECIES_NAME, CONTAMINANT) %>%
  summarize(outlier.low = min(residual, na.rm = T), outlier.high = max(residual, na.rm = T), 
            p95 = quantile(residual, p = 0.975, na.rm = T),
            p75 = quantile(residual, p = 0.75, na.rm = T), 
            median = quantile(residual, p = 0.5, na.rm = T), 
            p25 = quantile(residual, p = 0.25, na.rm = T), 
            p5 = quantile(residual, p = 0.025, na.rm = T), 
            influential.points = sum(residual < p5 | residual > p95)/n(), 
            mean.lower = ifelse(length(residual) > 4, t.test(residual, conf.level = .90)$conf.int[1], NA),
            mean.upper = ifelse(length(residual) > 4, t.test(residual, conf.level = .90)$conf.int[2], NA),
            outlier.high.text = ifelse(outlier.high > 10, paste0("max = ", round(outlier.high,2)), ""), 
            p97.5.text = ifelse(p95> 10, paste0("97.5% = ",round(p95, 2)), ""),
            outlier.high = ifelse(outlier.high > 10, Inf, outlier.high), 
            p95= ifelse(p95 > 10, Inf, p95)) %>%  
  arrange(response, CONTAMINANT, SPECIES_NAME, SEN) %>%
  group_by() %>%
  mutate(plotorder =paste(CONTAMINANT, SPECIES_NAME, response), 
         plotorder = factor(plotorder, levels = unique(plotorder)))


## plot the accuracy by the amount of contaminant being predicted

horizontal.lines = 2:length(unique((Residual.plotting %>% filter(CONTAMINANT == "Hg"))$plotorder))-1 + 0.5

plot.resids <- ggplot(Residual.plotting %>% filter(CONTAMINANT == "Hg"), aes(median, plotorder, yend = plotorder, group = SEN, color = SEN)) + 
  geom_point(position = position_dodge(width = 0.9), size = 3, shape = 21) +
  geom_vline(aes(xintercept = 0), color = "red", linewidth = 1) +
  geom_hline(yintercept = horizontal.lines, color = "grey77") +
  geom_errorbar(aes(xmin = p5, xmax = p95), position = position_dodge()) + 
  geom_errorbar(aes(xmin = outlier.low, xmax = outlier.high), linetype=2, width = 0, position = position_dodge(width = 0.9)) +
  geom_point(aes(x = outlier.low), position = position_dodge(width = 0.9), shape = 3) +
  geom_point(aes(x = outlier.high), position = position_dodge(width = 0.9), shape = 3) +
  geom_text(aes(x = 3, label = paste0(outlier.high.text, "\n", p97.5.text)), position = position_dodge(width = 0.9)) +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(position = "top") +
  theme_minimal() + 
  scale_color_manual(name = "Sample number", values = c("black", "grey55")) +
  theme(axis.title.x=element_text(color = "grey22", size = 15),
        axis.text.x=element_text(size = 10),
        axis.title.y=element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y=element_blank(), 
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = 3, color = "grey88")
        ) + xlab("Residual concentration (ug/g wet weight)")

plot.corrs <- ggplot(lm_sums %>% filter(CONTAMINANT == "Hg") %>%
  pivot_longer(cols = c(SPECIES_NAME, response, R2.text), names_to = "column", values_to = "text") %>% 
    mutate(column = gsub("response", "Model", column), 
           column = gsub("SPECIES_NAME", "Fish Species", column),
           column = gsub("R2.text", "Correlation", column)) %>% 
    mutate(column = factor(as.character(column), levels = c("Fish Species", "Model", "Correlation"))), aes(column, plotorder)) + 
  geom_text(aes(label = text)) +
  geom_hline(yintercept = horizontal.lines, color = "grey77") +
  scale_y_discrete(limits = rev) +
  theme_minimal() + 
  scale_color_manual(name = "Sample number", values = c("black", "grey55")) +
  scale_x_discrete(position = "top") +
  theme(axis.title.x=element_text(color = "white"),
        axis.text.x=element_text(color = "grey22", size =15),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(), 
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = 3, color = "grey88")
        ) 

ggarrange(plot.corrs, plot.resids, ncol =2, common.legend = T, align = "v")
```


```{r pred-resid-table-res-As, fig.width=8, fig.height=10.5, fig.cap="Table of [As] model prediction results for tissue of 400-600g and 900-1100g fish compared to measured values. The table includes a column of correlation statistics (r and p-value) for each model assessed in the study. To the right of the plot, a dot plot shows the distribution of model residuals for events with less than five fish (grey), or 5 or more fish (black). A central hollow circle designates the median, with a solid error bar designating the 2.5, and 95th percentiles of the distribution. A dashed line ending in a + is used to show the range of remaining residuals. A vertical red line is used to highlight where the distributions overlap with zero."}


## plot the accuracy by the amount of contaminant being predicted

horizontal.lines = 2:length(unique((Residual.plotting %>% filter(CONTAMINANT == "As"))$plotorder))-1 + 0.5

plot.resids <- ggplot(Residual.plotting %>% filter(CONTAMINANT == "As"), aes(median, plotorder, yend = plotorder, group = SEN, color = SEN)) + 
  geom_point(position = position_dodge(width = 0.9), size = 3, shape = 21) +
  geom_vline(aes(xintercept = 0), color = "red", linewidth = 1) +
  geom_hline(yintercept = horizontal.lines, color = "grey77") +
  geom_errorbar(aes(xmin = p5, xmax = p95), position = position_dodge()) + 
  geom_errorbar(aes(xmin = outlier.low, xmax = outlier.high), linetype=2, width = 0, position = position_dodge(width = 0.9)) +
  geom_point(aes(x = outlier.low), position = position_dodge(width = 0.9), shape = 3) +
  geom_point(aes(x = outlier.high), position = position_dodge(width = 0.9), shape = 3) +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(position = "top") +
  theme_minimal() + 
  scale_color_manual(name = "Sample number", values = c("black", "grey55")) +
  theme(axis.title.x=element_text(color = "grey22", size = 15),
        axis.text.x=element_text(size = 10),
        axis.title.y=element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y=element_blank(), 
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = 3, color = "grey88")
        ) + xlab("Residual concentration (ug/g wet weight)")

plot.corrs <- ggplot(lm_sums %>% filter(CONTAMINANT == "As") %>%
  pivot_longer(cols = c(SPECIES_NAME, response, R2.text), names_to = "column", values_to = "text") %>% 
    mutate(column = gsub("response", "Model", column), 
           column = gsub("SPECIES_NAME", "Fish Species", column),
           column = gsub("R2.text", "Correlation", column)) %>% 
    mutate(column = factor(as.character(column), levels = c("Fish Species", "Model", "Correlation"))), aes(column, plotorder)) + 
  geom_text(aes(label = text)) +
  geom_hline(yintercept = horizontal.lines, color = "grey77") +
  scale_y_discrete(limits = rev) +
  theme_minimal() + 
  scale_color_manual(name = "Sample number", values = c("black", "grey55")) +
  scale_x_discrete(position = "top") +
  theme(axis.title.x=element_text(color = "white"),
        axis.text.x=element_text(color = "grey22", size =15),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(), 
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = 3, color = "grey88")
        ) 

ggarrange(plot.corrs, plot.resids, ncol =2, common.legend = T, align = "v")
```


We found that mixed effects approaches performed better than SER by enabling prediction of values for low sample sizes with increased or comparable accuracy to SER (Figure\@ref(fig:pred-resid-table-fig-Hg), \@ref(fig:pred-resid-table-res-As), Figure S\@ref(fig:pred-1000g-rem)). The REML, MCMC and INLA values were generally more strongly correlated to actual concentrations (r ranging from 0.73 - 0.99) than predictions from SER models (r ranging from 0.48 – 0.84) (Figure\@ref(fig:pred-resid-table-fig-Hg), \@ref(fig:pred-resid-table-res-As)), Figure S\@ref(fig:pred-1000g-rem)). Also, the residuals for the different mixed modeling approaches were generally similar or smaller than those of the SER approach, as observed the distributions of residuals shown in Figures \@ref(fig:pred-resid-table-fig-Hg) and \@ref(fig:pred-resid-table-res-As). Interestingly, attempts to improve the REML approach with bootstrapping did not increase accuracy of predictions, even resulting in decreased correlation strengths in some cases (specifically for the [Hg] Northern Pike and Lake Trout models, and the [As] Walleye model) (Figure\@ref(fig:pred-resid-table-fig-Hg) and \@ref(fig:pred-resid-table-res-As)). This is likely because the bootstrapping process overfit the models, as demonstrated by decreased RMSE (Figure\@ref(fig:RMSE-N-WE)), which reduced the ability of the models to produce generalized predictions. All of the mixed modeling methods were able to achieve the same level of accuracy in lakes with <5 fish as in larger sampling events, effectively increasing the size of the dataset that could produce predictions. It is likely that the increase in correlation of the mixed modelling approaches may just be a result of the increased sample size these approaches offer. Though the mixed model approach was only required for improving prediction when there was known bioaccumulation (i.e., for [Hg]), the accuracy of mixed model approaches were always comparable or better than SER or basic population means. Mixed model approaches improved prediction for datasets with less than 6000 training fish, which would be applicable to many studies. Nevertheless, the mixed model approaches are a suitable solution for contaminant prediction in a variety of dataset sizes and contaminants of variable bioaccumulative potential.  


```{r pred-fish-num, fig.width=8, fig.height=10, fig.cap = "Predicted concentration of [As] and [Hg] in fish tissue of 400-600g and 900-1100g fish compared to known values for models built with different maximum numbers of fish in training events. Points represent the correlations of predicted contaminant concentrations to measured values for the test dataset.", include=TRUE}
max.n.fish <- Boot_LMER_data_by_N %>% 
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  summarize(max_N_fish = max(N_fish))

## Lm summaries for REML
lm_sums_LMER <- LMER_fish_data %>% 
         filter(response %in% c("REML_logfit")) %>% 
  mutate(predicted = exp(predicted_value)) %>%
  group_by(CONTAMINANT, maxfish) %>%
  mutate(text.x = ifelse(CONTAMINANT=="As", 0.075, 1.5), text.y =0.005) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$response, .$maxfish)) %>%
  discard(~ nrow(.x)<3) %>%
    map(~ list(mod = cor.test(.x$predicted,.x$VALUE), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(Cor = round(.x$mod$estimate, 2),
                     p = round(.x$mod$p.value, 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         response = factor(str_extract(set, "SER|boot_REML|REML|MCMC|INLA_ll|INLA"), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll")),
         maxfish = str_extract(set, "[[:digit:]]+"))

lm_sums_LMER <- lm_sums_LMER %>% 
  left_join(max.n.fish) %>% 
  mutate(keep = as.numeric(maxfish) <= max_N_fish) %>% 
  filter(keep)

max.n.fish <- INLA_data_by_N %>% 
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  summarize(max_N_fish = max(N_fish))

## Lm summaries for INLA
lm_sums_INLA <- INLA_fish_data %>% 
         filter(response %in% c("INLA_fit")) %>% 
  mutate(predicted = exp(predicted_value)) %>%
  group_by(CONTAMINANT, maxfish) %>%
  mutate(text.x = ifelse(CONTAMINANT=="As", 0.075, 1.5), text.y =0.005) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$response, .$maxfish)) %>%
  discard(~ nrow(.x)<3) %>%
    map(~ list(mod = cor.test(.x$predicted,.x$VALUE), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(Cor = round(.x$mod$estimate, 2),
                     p = round(.x$mod$p.value, 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         response = factor(str_extract(set, "SER|boot_REML|REML|MCMC|INLA_ll|INLA"), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll")),
         maxfish = str_extract(set, "[[:digit:]]+"))


lm_sums_INLA <- lm_sums_INLA %>% 
  left_join(max.n.fish) %>% 
  mutate(keep = as.numeric(maxfish) <= max_N_fish) %>% 
  filter(keep)

lm_sums <- rbind(lm_sums_LMER, lm_sums_INLA)

## plot the accuracy by the amount of contaminant being predicted
plot1 <- ggplot(lm_sums %>% mutate(maxfish = as.numeric(maxfish)) %>%
         filter(CONTAMINANT=="As") %>% group_by(), aes(maxfish, Cor, color = response)) + 
  geom_point(alpha=0.25, aes(shape = p<0.05)) +
  geom_line()+
  ylab("corellation of predicted values to measured values") + xlab("Max number of Fish in training event") +
  facet_grid(CONTAMINANT+SPECIES_NAME~.) + 
  theme_minimal() 

plot2 <- ggplot(lm_sums %>% mutate(maxfish = as.numeric(maxfish)) %>%
         filter(CONTAMINANT=="Hg") %>% group_by(), aes(maxfish, Cor, color = response)) + 
  geom_point(alpha=0.25, aes(shape = p<0.05)) +
  geom_line()+
  ylab("corellation of predicted values to measured values") + xlab("Max number of Fish in training event") +
  facet_grid(CONTAMINANT+SPECIES_NAME~.) + 
  theme_minimal() 

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```



We found that the INLA approach performed  just as well with fewer data points from individual sampling events, but that some higher N lakes were required to retain optimum model performance. This was shown in the [Hg] INLA models, where optimum prediction accuracy was not reached until there was a sample event with 16, 7 and 11 fish for lake trout, northern pike and walleye, respectively (Figure \@ref(fig:pred-fish-num)). INLA [As] models performed well for all sample sizes assessed, likely because of the low bioaccumulation potential. The REML approach had a similar pattern, but generally required a higher maximum sample size to optimize prediction accuracy compared to INLA, and also had unpredictable changes in accuracy based on the maximum number of fish that were allowed per sample event (Figure \@ref(fig:pred-fish-num)). Northern pike and walleye mercury concentrations were predicted more accurately with fewer values included per lake, but all other models had increased accuracy with the inclusion of more data in the training set. The highest maximum number of individual fish for a sampling event required for a stable correlation from INLA modelling was 16 fish, in the lake trout mercury dataset. This suggests that models will be most effective when at least some lakes with more than 15 fish are included in the dataset. Most of the models performed well at lower numbers of fish per sampling event (12 or less fish) (Figure \@ref(fig:pred-fish-num)). This suggests that sampling regimes should include some, slightly higher intensity sampling lakes, but that there would be marginal utility to sampling more than 12 fish in any individual sampling event. It also showed that INLA has predictable increases in prediction accuracy with the inclusion of more data, without becoming overfit when additional data is included.


```{r RMSE-N-WE, fig.width = 10, fig.height = 7, fig.cap= "Root mean squared error (RMSE) from sampling events trained with different numbers of fish. RMSE of training set sampling events are compared to the number of fish used from the sampling event that were included in the training dataset. For events with less than 5 fish, and events with 5 or more fish, a boxplot displays the 25th and 75th percentiles and the median RMSE, with the whiskers extending out to 1.5 x the interquartile range. The figure shows data for [As] and [Hg] Sample event regressions (SER), restricted maximum likelihood (REML), restricted maximum likelihood with bootstrapping (boot_REML), Markhov Chain Monte Carlo (MCMC) and Integrated Laplace Approximation (INLA) models."}
# plot model accuracies against number of fish used to produce the model
ggplot(models_RMSE %>% 
         mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll")), Fish_cat = N_fish > 4) %>% filter(!response == "INLA_ll"),
       aes(response, predicted_value, color = Fish_cat)) +
  geom_boxplot(aes(group = paste(Fish_cat, response)), alpha = 0.2)  +
  facet_grid(CONTAMINANT+SPECIES_NAME~., scales = "free") + ylab("RMSE") + xlab("Approach") + theme_minimal() +
  scale_color_manual(name = "Number of fish", labels = c("4 or less", "5 or more"), values = c("grey55", "black"))


```


Differences in the fits of values to the different sampling events illustrated how the well the different approaches could explain the data in that training set. INLA and MCMC models were more tightly fitted to the training data for the distinct sampling events, shown by lower RMSE, with fits comparable to those of SER (Figure \@ref(fig:RMSE-N-WE)). Conversely, REML approaches generally had distributions with a wider range of RMSE, including more large RMSE points for various sample-sizes. These high influential values indicated that the patterns in some sampling events were more poorly represented than others in the global model. Boot_REML models often had the highest fits to the training data, with lower RMSE than the other mixed model approaches or SER, but this did not correspond to the best predictive accuracy The low sample number events typically had lower RMSEs, presumably because fewer values were fit by the mixed model. All approaches had RMSE that generally increased and stabilized at about 6 fish sampling events but had fairly comparable RMSE at event sizes below 6, with the exception of some events with substantial influential points (Figure S\@ref(fig:extra-RMSE-N)). These results suggest that a minimum sample size of 6 fish/population should be collected by monitoring and research programs when size standardized contaminants will be determined, to minimize overfitting MCMC and INLA generally appeared to have fewer large influential RMSE values, and a more even distribution of RMSE for the different sampling events. The improved performance of the MCMC and INLA approaches do not appear to have these limitations, they are more adept at tuning the lake-level slope and intercept parameters, and thus improved precision of the model fit[@sonesten2003;@somers1993;@INLA2009a; @INLA2013a]. Understanding the model fit of predictive approaches is not always necessary to ensure predictive accuracy, as higher fits can be higher due to exclusion of influential values or lack of balance in a dataset. However, many researchers are interested in the relationships involved with these predictions. Size-concentration relationships can provide insight into bioaccumulation differences between waterbodies. The improved fit of the INLA and MCMC approaches showed that these approaches were better at explaining the patterns in the training data than REML, and these increased fits had little or no cost to predictive accuracy (i.e., the models are better at predicting the general population trends). Thus, if a researcher is interested in the mechanisms of prediction, the Bayesian approaches would be suitable options.


## Relative computational requirements
```{r Times}

### Compile times into one dataframe
model_times <- rbind(SER_times, LMER_times %>% mutate(method = gsub("Boot.", "boot_", method)), RSTAN_times, INLA_times) %>% 
         mutate(method = factor(method, levels = c("SER", "REML", "boot_REML", "MCMC", "INLA")), 
                SPECIES_NAME = tolower(SPECIES_NAME)) %>% 
  group_by(SPECIES_NAME, CONTAMINANT) %>%
  pivot_wider(names_from = method, values_from = run.time) %>%
  arrange(CONTAMINANT, SPECIES_NAME) %>%
  dplyr::rename('Contaminant' = CONTAMINANT, 'Species'= SPECIES_NAME) %>% 
  dplyr::select(Contaminant, Species, SER, REML, boot_REML, MCMC, INLA)

## Table of model times - not even bothering with global RMSE
knitr::kable(model_times, caption = "RMSE for the global model for each modeling approach compared to the computation time required to perform it. The time in seconds, is presented for each modelling approach for each species and contaminant combination. Computation time ranged from less than one second to 47248 seconds (13.1 hours) across approaches and species.")

```


While our results show the benefit of using Bayesian modeling approaches when size-standardizing contaminant concentrations in fish, they are more complex and thus, can have higher computational requirements. Overall, INLA models were much less computationally intensive compared to the MCMC and REML_boot implementations. While REML was the quickest of all modeling approaches, INLA was a close second, with times orders of magnitude lower than REML_boot or MCMC (Table \@ref(tab:Times)).  As the overall accuracy of the INLA approach is improved compared to REML approach, and it had improved speed compared to the MCMC approach we tested in this study, we suggest that INLA is the most viable alternative to standardizing values via the SER approach, that may allow for incorporation of more data into analyses. 


Each modelling approach had different benefits and drawbacks in terms of implementation. Application of each approach varied in difficulty, going from REML<SER<MCMC<INLA. The REML approach was simple enough that any beginner R user could implement it quickly, without requiring knowledge of loops or other programming. The SER approach required more programming knowledge in order to implement it efficiently, and a significant amount of pre-screening of data to ensure that data used for linear models covered a large enough span to develop a curve. There were more documentation and reading requirements to implement the MCMC and INLA models. These requirements mean there is a higher risk of incorrect implementation of INLA models with the current INLA package implementation, since the model formula input deviates from the typical R notation. There is thorough documentation of the model notation in the INLA package, but it is nonetheless a consideration in the implementation of this approach, as it added complexity when assessing the nested random effect of waterbody and sampling event. The [As] models were generally more difficult to fit due to lower sample sizes, requiring different settings, while [Hg] models ran well on the default settings of the lmer, stan_glmer and inla functions. Conceptually, the SER approach is the most simple to understand, given that it is essentially a group of independent linear models. The REML, MCMC and INLA are all more conceptually challenging, however, there is quite a jump in the complexity of a Bayesian model from the REML approach. Comparatively, understanding of the Bayesian (MCMC), and the approximated Bayesian (INLA) approach are again more complex, which should be considered when model tuning is required, which would likely be required for smaller datasets (<300). Relatively few studies[@visha2015; @visha2018; @kluke2022] have used Bayesian approaches to account for size effects, compared to more traditional linear modelling. This may be, in part, due to the lack of guidelines for the best practices during implementation. For researchers pursuing predictive accuracy alone, the REML approach may be the best option due to the ease of implementation. Researchers interested in the underlying effects driving the predictions may find the additional effort to use INLA or MCMC models worthwhile, as these models had stronger fits to the training data while maintaining predictive accuracy. Additionally, the information from these models can inform sample size adjustments: intercepts can inform if the number of samples are lacking and slopes can indicate if the range of sizes are insufficient.


Mixed model approaches show promise for increasing predictive power for estimating contaminant concentrations in fish by leveraging the predictive power from sampling events across time and space. We found that REML MCMC, and INLA models were effective tools to predict contaminant concentrations with models of contaminant-size relationships of three fish species for two contaminants with different bioaccumulative potentials. Though the improvement on performance was much more pronounced on the smaller datasets, these techniques have more consistent performance across sample sizes, and are a good option when the bioaccumulative potential of a contaminant is unknown. The REML was the most easily implemented However, this approach was sensitive to sample size, and was not able to perform as well as INLA at lower sample numbers. REML also had poorer model fit to the training data, meaning it is less suitable for explaining the effects driving the size-contaminant relationships. INLA was generally the least computationally intensive option, and had less RMSE in the models, making it suitable for both explanatory and predictive applications. INLA can be performed quickly, without high performance computing requirements. INLA also had comparable predictive accuracy at ~12 or fewer samples to the full dataset, which may allow for reductions in sampling effort for studies that intend to use a size-standardized contaminant concentration. In summary, we suggest INLA is a suitable option for size-adjustment of contaminant concentrations in fish with the potential to increase sample sizes. Use of these tools can enable greater power in investigations of important environmental drivers of contaminants in fish.      



<!---
extra stuff
In freshwater systems, [Hg] typically ranges from …. for Lake Trout, … for Northern Pike and … for Walleye, which align quite well with the range we observed in the data …. for Lake Trout, … for Northern Pike and … for Walleye. The higher variance in response of the REML approaches is likely because of the limited capability for this approach to account for uncertainty in random effects, and it appears that our bootstrapping implementation did little to correct for this issue.
but also have applications for studying polar bear [@verreault2005], moose [@danielsson2009] and even human populations [@pal2013].
Small sample sizes can be particularly limiting in assessments of temporal trends, and may lead researchers to pool samples over time periods, such as in Bhavsar *et al.,* [-@bhavsar2010].

Some contaminants are widely acknowledged as requiring size adjustment, and have rich datasets that enable SER on many populations, while others may be limited by cost of analyses and additional sampling requirements. Mercury ([Hg]) is a highly bioaccumulative contaminant of global concern that is routinely monitored in fish. Mercury is well known to accumulate in the muscle tissue of fish, because of its chemical speciation and inter-organ transport [@peng2016]. Many studies have found strong positive correlations between Hg concentrations and body size in both freshwater [@johnston2022] and marine [@al-sulaiti2022] environments and, thus, size-adjustments of Hg concentrations prior to making comparisons across environmental gradients are common [@lescord2020;@sumner2020;@eagles-smith2016;@eckley2023;@negrazis2022], and datasets as a result are suited to this approach. Other contaminants, like arsenic, are less bioaccumulative in fish, showing mixed and weaker relationships with metrics of body size [@lescord2020;@kluke2022]. Arsenic also represents a contaminant that is more costly to analyze, meaning there may be less data covering a wide range of sizes. Arsenic is a good example of a weakly bioaccumulative contaminant that poses significant concern. Depending on its chemical speciation, arsenic can be a harmful carcinogenic contaminant, but it is less widely distributed and often originates from a localized point source of contamination or natural abundance. It is also less routinely monitored and researched when compared to [Hg] in fish[@lescord2020; @ontario2023], which results in less data to be available for size-adjustment models [@ponton2022]. Not accounting for size in population-level comparisons of contaminants could mean that size-related variation could be incorrectly attributed to other attributes of a sample, possibly weakening predictions and limiting our understanding of environmental cycling and bioaccumulation patterns. Many emerging contaminants of concern face similar issues of unknown or low bioaccumulative potential, and a lack of data for effective size-adjustment using SER.
--->


# Acknowledgements



# Data Accessibility


The processed data, scripts used to create this manuscript, and the INLA example code are available for download at the public repository managed by the WETlab at the Great Lakes Forestry Centre:  [https://github.com/GLFC-WET/HGAS_master](https://github.com/GLFC-WET/HGAS_master)



# Supplemental Tables

```{r sampling-events-summary}

test_fish <- models_accuracy_by_N %>% 
         filter(response %in% c("REML_resid", "boot_resid", "SER_residuals", "INLA_resid", "MCMC_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_REML", response)), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA"))) %>% 
  group_by(CONTAMINANT, response, SPECIES_NAME) %>% 
  summarize(test.fish = n(), 
            test.events = length(unique(paste0(WATERBODY_CODE, SAMPLE_YEAR))))

train_fish <- all_contaminants %>% # split the dataset by contaminant, species for each waterbody and sampling year
  group_by(CONTAMINANT, SPECIES_NAME) %>% 
  summarize(train.fish = n(), 
            train.events = length(unique(paste0(WATERBODY_CODE, SAMPLE_YEAR))))

train_fish <- rbind(cbind(train_fish, response = "INLA"), 
                    cbind(train_fish, response = "MCMC"), 
                    cbind(train_fish, response = "REML"), 
                    cbind(train_fish, response = "boot_REML"))

SER_train_fish <- all_contaminants %>% # split the dataset by contaminant, species for each waterbody and sampling year
  group_by(CONTAMINANT, SPECIES_NAME, EVENT)%>% 
  filter(!is.na(VALUE_LOG_TRAIN)) %>%
  mutate(min_weights = min(WEIGHT_GRAM),
         max_weights = max(WEIGHT_GRAM)) %>% 
                   ## Need to ensure the weights of the fish used to create the log-weight model span the weights we are going to standardize to
  filter((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000)) %>% 
  filter(n() >= 5) %>%
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  summarize(train.fish = n(), 
            train.events = length(unique(paste0(WATERBODY_CODE, SAMPLE_YEAR)))) %>% 
  mutate(response = "SER")

train_fish = rbind(train_fish, SER_train_fish)

test_train <- left_join(test_fish, train_fish) %>%
  mutate(fish = paste(train.fish, test.fish, sep = " / "), 
         events = paste(train.events, test.events, sep = " / "),
         fish.events = paste(train.fish, "(",train.events, ")/", test.fish, "(",test.events, ")", sep = "")) %>% 
  group_by(CONTAMINANT, SPECIES_NAME)
```


```{r fish-summary}
  test_train %>% 
  dplyr::select(fish.events, response) %>% 
  pivot_wider(names_from = response, values_from= fish.events) %>% 
  knitr::kable(caption = "Summary of number fish for each contaminant and species in the dataset used in this analysis. Values are listed as 'train / test' for each dataset.")

```


```{r model-estimates, eval = FALSE}
## This chunk creates a table output of the model estimates from each approach. 
INLA_effects <- INLA_data %>% 
  map(~ cbind(rbind(data.frame(.x$estimates$fixed.effect)), method = "MCMC")) %>% 
  bind_rows(.id = "set") 
```


# Supplemental Figures


```{r response-values, fig.width=10.5, fig.cap = "Number of fish at different body weights and contaminant concentrations for [As] and [Hg]. Vertical black lines show the weights that are commonly used for standardization."}
main = ggplot(all_contaminants %>% filter(CONTAMINANT == "As"), aes(WEIGHT_GRAM, VALUE, color = SPECIES_NAME)) + 
  geom_point() +  
  theme_minimal() + theme(axis.title = element_blank(), axis.text = element_blank(), plot.margin = unit(c(0, 0, 0, 0), "inches")) + scale_y_log10() + scale_x_log10()

conc <- ggplot(all_contaminants%>% filter(CONTAMINANT == "As"), aes(VALUE, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  theme_minimal() + xlab("[As] ug/g wet weight") +ylab("")+ coord_flip() + scale_x_log10()+scale_y_reverse() + theme(plot.margin = unit(c(0, 0, 0, 0), "inches"), axis.text.x = element_blank())

weight = ggplot(all_contaminants%>% filter(CONTAMINANT == "As"), aes(WEIGHT_GRAM, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  geom_vline(xintercept = c(400, 1100))+ scale_x_log10() +scale_y_reverse()+ xlab("wet weight (g)") +ylab("") + theme(plot.margin = unit(c(0, 0, 0, 0), "inches"), axis.text.y = element_blank())

plots_As<- ggarrange(conc, main, NULL, weight, 
                     widths = c(0.25, 1), heights = c(1, 0.3), 
                     ncol =2, nrow = 2, 
                     common.legend = T,
                     align = "hv")

main = ggplot(all_contaminants %>% filter(CONTAMINANT == "Hg"), aes(WEIGHT_GRAM, VALUE, color = SPECIES_NAME)) + 
  geom_point() +  
  theme_minimal() + theme(axis.title = element_blank(), axis.text = element_blank(), plot.margin = unit(c(0, 0, 0, 0), "inches")) + scale_y_log10() + scale_x_log10()

conc <- ggplot(all_contaminants%>% filter(CONTAMINANT == "Hg"), aes(VALUE, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  theme_minimal() + xlab("[Hg] ug/g wet weight") +ylab("")+ coord_flip() + scale_x_log10()+scale_y_reverse() + theme(plot.margin = unit(c(0, 0, 0, 0), "inches"), axis.text.x = element_blank())

weight = ggplot(all_contaminants%>% filter(CONTAMINANT == "Hg"), aes(WEIGHT_GRAM, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  geom_vline(xintercept = c(400, 1100))+ scale_x_log10() +scale_y_reverse()+ xlab("wet weight (g)") +ylab("") + theme(plot.margin = unit(c(0, 0, 0, 0), "inches"), axis.text.y = element_blank())

plots_Hg<- ggarrange(conc, main, NULL, weight, 
                     widths = c(0.25, 1), heights = c(1, 0.3), 
                     ncol =2, nrow = 2, 
                     common.legend = T,
                     align = "hv")

ggarrange(plots_As, plots_Hg, common.legend = T,
                     align = "hv", ncol =2)
```



```{r pred-1000g-rem, fig.width=10, fig.height=8.5, fig.cap = "Predicted concentration of [As] and [Hg] in tissue of 400-600g and 900-1100g fish compared to measured values. Points display each individual fish prediction (with blue points representing predictions at sampling events with less than 5 fish, and black points representing predictions from sampling events with at least 5 fish) and a solid red line shows a 1-1 relationship. The dashed red lines provide an interval for predicted values that are within 25% of the measured value. Correlation statistics are included where there were enough values to compute them. Axes are shown on a log scale, as values were modelled from log-transformed values."}
## Calculate the straight means and include with the rest of the values as a comparison for the Arsenic predictions
mean_mods <- all_contaminants %>%
  # split the dataset by contaminant, species for each waterbody and sampling year
  group_by(CONTAMINANT, SPECIES_NAME, EVENT) %>%
  mutate(mean_logfit = median(VALUE_LOG_TRAIN, na.rm = T)) %>% 
  mutate(predicted_value = mean_logfit,
         response = "mean_logfit",
         N_fish = sum(is.na(VALUE_LOG_TEST))) %>%
  filter(!is.na(VALUE_LOG_TEST), CONTAMINANT == "As") %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, N_fish, response, predicted_value, LENGTH_CM, LENGTH_CM_LOG, EVENT, test_train, VALUE_LOG_TEST, VALUE_LOG_TRAIN)


## Lm summaries
lm_sums <- models_accuracy_by_N %>% rbind(mean_mods) %>%
         filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit", "mean_logfit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA"))) %>%
  mutate(predicted = exp(predicted_value)) %>%
  group_by(CONTAMINANT) %>%
  mutate(text.x = ifelse(CONTAMINANT=="As", 0.1, 1.5), text.y =0.02) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$response)) %>%
  discard(~ nrow(.x)<3) %>%
    map(~ list(mod = cor.test(.x$predicted,.x$VALUE), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(Cor = round(.x$mod$estimate, 2),
                     p = round(.x$mod$p.value, 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         response = factor(str_extract(set, "SER|mean|boot_REML|REML|MCMC|INLA_ll|INLA"), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll")),
         R2.text = paste0("cor = ", Cor, "\np ",ifelse(p < 0.05, "< 0.05", paste0("= ", p))))

## plot the accuracy by the amount of contaminant being predicted
plot1 <- ggplot(models_accuracy_by_N %>% rbind(mean_mods) %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more")) %>%
         filter(CONTAMINANT=="As") %>% 
         filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit", "mean_logfit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA"))), aes(VALUE, exp(predicted_value), color = SEN)) + 
  geom_point(alpha=0.25, shape = 20, size = 2) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F, color = "black")+
  ylab("Predicted concentration (ug/g wet weight)") + xlab ("Actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response) + 
  theme_minimal() + 
  scale_color_manual(values = cust_cols) +
  scale_y_log10() + scale_x_log10()

plot2 <- ggplot(models_accuracy_by_N %>% 
         filter(CONTAMINANT=="Hg") %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more"))%>% 
         filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA"))), aes(VALUE, exp(predicted_value), color = SEN)) + 
  geom_point(data = models_accuracy_by_N %>%  
         filter(CONTAMINANT=="Hg") %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more"))%>% 
          filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA"))) %>% filter(SEN == "5 fish or more"), alpha=0.1, shape = 20, size = 2) +
    geom_point(data = models_accuracy_by_N %>% filter((WEIGHT_GRAM >= 495 & WEIGHT_GRAM <= 505)|(WEIGHT_GRAM >= 995 & WEIGHT_GRAM <= 1005)) %>% 
         filter(CONTAMINANT=="Hg") %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more"))%>% 
          filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit")) %>% 
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA"))) %>% filter(SEN == "less than 5 fish"), alpha=0.25, shape = 20, size =2) +
  #geom_smooth()+
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F, color = "black")+
  ylab("Predicted concentration (ug/g wet weight)") + xlab ("Measured concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response) + 
  theme_minimal() + 
  scale_color_manual(values = cust_cols)#+
  #scale_y_log10() + scale_x_log10()

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```


```{r extra-RMSE-N, fig.width = 10, fig.height = 7,  fig.cap= "Root mean squared error (RMSE) of models from sampling events trained with different numbers of fish. RMSE of training set sampling events are compared to the number of fish used from the sampling event that were included in the training dataset. For each N, a boxplot displays the 25th and 75th percentiles and the median RMSE, with the whiskers extending out to 1.5 x the interquartile range. A line is plotted across the median values to show the overall trend in the values."}
# plot model accuracies against number of fish used to produce the model
ggplot(models_RMSE %>% 
         mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll"))) %>% filter(!response == "INLA_ll") ,
       aes(N_fish, predicted_value)) +
  geom_boxplot(aes(group = paste(N_fish, response)), alpha = 0.2) + 
  geom_line(data = models_RMSE %>% 
         mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll"))) %>% filter(!response == "INLA_ll") %>% 
              group_by(SPECIES_NAME, CONTAMINANT, N_fish, response)%>% 
              summarize(predicted_value = median(predicted_value))
            ) +
  facet_grid(response~CONTAMINANT+SPECIES_NAME , scales = "free_x") + ylab("RMSE") + xlab("Number of Fish used from sampling event used in model training") + theme_minimal()


```


```{r resid-fig-extra, fig.width = 14, fig.height = 8, fig.cap = "Residuals of predicted fish values for each sample event."}

## Calculate the straight means and include with the rest of the values as a comparison for the Arsenic predictions
mean_mods <- all_contaminants %>%
  # split the dataset by contaminant, species for each waterbody and sampling year
  group_by(CONTAMINANT, SPECIES_NAME, EVENT) %>%
  mutate(mean_logfit = mean(VALUE_LOG_TRAIN, na.rm = T)) %>% 
  mutate(predicted_value = mean_logfit,
         response = "mean_logfit",
         N_fish = sum(is.na(VALUE_LOG_TEST))) %>%
  filter(!is.na(VALUE_LOG_TEST), CONTAMINANT == "As") %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, N_fish, response, predicted_value, LENGTH_CM, LENGTH_CM_LOG, EVENT, test_train, VALUE_LOG_TEST, VALUE_LOG_TRAIN)


## plot the accuracy by the amount of contaminant being predicted
plot1 <- ggplot(models_accuracy_by_N %>% rbind(mean_mods) %>% mutate(EVENT = paste0(WATERBODY_CODE, "_", "SAMPLE_YEAR")) %>%
         mutate(SEN = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more")) %>%
         filter(response %in% c("REML_logfit", "boot_log_fit", "SER_logfit", "INLA_log_fit", "MCMC_log_fit"))%>%
                  mutate(residual = exp(predicted_value) - VALUE) %>%
         mutate(response = factor(gsub("_logfit|_log_fit", "", gsub("boot", "boot_REML", response)), levels = c("SER", "mean", "REML", "boot_REML", "MCMC", "INLA"))), aes(EVENT, residual, color = SEN)) + 
  geom_boxplot() +
  ylab("Residual concentration (ug/g wet weight)") + xlab ("Sampling event") +
  facet_grid(SPECIES_NAME+CONTAMINANT~response, scale = "free_y") + 
  theme_minimal() + 
  scale_color_manual(values = cust_cols) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

plot1
```



```{r predictions-SER-WE, fig.height=10, fig.width = 8, fig.cap = "Predicted concentration of [As] and [Hg] of 500g and 1000g fish compared to predictions via SER. Points display each individual fish prediction and a solid red line shows a 1-1 relationship. The dashed red lines provide an interval for predicted values that are within 25% of the predicted SER value. Correlation statistics are included in the top left of each panel."}
#Plot comparison of predicted Hg and As content of 500g and 1000g fish for each technique against The SER value
## fill in missing N_fish information
predicted_data_4plot <- predicted_data %>% group_by(SAMPLE_YEAR, SPECIES_NAME, WATERBODY_CODE, CONTAMINANT) %>% 
  mutate(N_fish = ifelse(sum(is.na(N_fish)) == n(), 0, unique(N_fish[N_fish>0]))) %>%
  mutate(`Fish in sample event` = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more")) %>% group_by() %>%
  mutate(pred.lower = as.numeric(pred.lower), 
         pred.upper = as.numeric(pred.upper), 
         pred.fit = as.numeric(pred.fit), 
         N_fish = ifelse(is.na(N_fish), 0, N_fish)) %>%
  mutate(method = factor(as.character(method), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA", "INLA_ll"))) %>% 
  filter(!N_fish == 0, (SPECIES_NAME == "Lake Trout" & CONTAMINANT == "Hg")|(SPECIES_NAME == "Northern Pike" & CONTAMINANT == "As")) %>% filter(!method == "INLA_ll")

## prepare for plotting against SER predictions
pred.plot <- predicted_data_4plot %>% pivot_wider(id_cols = c("N_fish", "SAMPLE_YEAR", "SPECIES_NAME", "WATERBODY_CODE", "CONTAMINANT", "WEIGHT_GRAM"), names_from = method, values_from = pred.fit, values_fn = mean) %>%
  pivot_longer(cols = c(MCMC, INLA, REML, boot_REML), values_to = "pred.fit", names_to = "method")%>%
  mutate(method = factor(as.character(method), levels = c("REML", "boot_REML", "MCMC", "INLA"))) %>%
  mutate(`Fish in sample event` = ifelse(N_fish < 5, "less than 5 fish", "5 fish or more"))
  
## Lm summaries
lm_sums <- pred.plot %>% 
  group_by(CONTAMINANT) %>%
  mutate(text.x = exp(min(log(SER), na.rm = TRUE)*.85), text.y = exp(quantile(log(pred.fit), probs = 0.95, na.rm = TRUE))) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$method)) %>%
  discard(~ nrow(.x) == 0) %>%
    map(~ list(mod = cor.test(.x$pred.fit,.x$SER), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(Cor = round(.x$mod$estimate, 2),
                     p = round(.x$mod$p.value, 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         method = factor(str_extract(set, "SER|boot_REML|REML|MCMC|INLA"), levels = c("SER", "REML", "boot_REML", "MCMC", "INLA")),
         R2.text = paste0("cor = ", Cor, "\np ",ifelse(p < 0.05, "< 0.05", paste0("= ", p))))


## plots for each size prediction  
plot1 <- ggplot(pred.plot %>% filter(CONTAMINANT == "As"), aes(SER, pred.fit, color = `Fish in sample event`))+ 
  geom_point(alpha = 0.25)+ 
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F, color = "black")+
  facet_grid(CONTAMINANT+SPECIES_NAME~method)+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") +
  scale_y_log10() + scale_x_log10()

plot2 <- ggplot(pred.plot %>% filter(CONTAMINANT == "Hg"), aes(SER, pred.fit, color = `Fish in sample event`))+ 
  geom_point(alpha = 0.25)+ 
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F, color = "black")+
  facet_grid(CONTAMINANT+SPECIES_NAME~method)+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") +
  scale_y_log10() + scale_x_log10()

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```


The MCMC and INLA approaches both had predicted values that performed very comparably with SER predictions (most correlations greater than 0.9), with most values greater than 1 ug/g~wet\ weight~ falling within 25% of the predicted SER values. The values lower than 1 ug/g~wet\ weight~ had more variance than this, but stayed within approximately 0.5 ug/g~wet\ weight~(Figure \@ref(fig:predictions-SER-WE)). Predictions from REML and REML-bootstrapped approaches were consistent with each other, and had a general association with predicted values from SER, but much more noise in the predictions than the MCMC or INLA approaches (most correlations between to 0.74-0.91).

# References


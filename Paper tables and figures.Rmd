---
title: "Mixed effects model approaches for estimating size-adjusted contaminant concentrations in fish populations."
author: 
- \* Emily Smenderovac (corresponding author), Great Lakes Forestry Centre, Natural Resources Canada, emily.smenderovac@nrcan-rncan.gc.ca
- Brian W. Kielstra, Great Lakes Forestry Centre, Natural Resources Canada, bkielstra@ecometrix.ca
- Tom Johnston, Living with Lakes Centre, Laurentian University, Ontario Ministry of Natural Resources and Forestry, tjohnston@laurentian.ca
- Satyendra Bhavsar, Ontario Ministry of the Environment and Climate Change, satyendra.bhavsar@ontario.ca
- Rob Mackereth, Centre of Excellence for Sustainable Mining and Exploration, Ontario Ministry of Natural Resources and Forestry, rob.mackereth@ontario.ca
- Stephanie Melles, Department of Chemistry and Biology, Toronto Metropolitan University, stephanie.melles@torontomu.ca 
- Gretchen L. Lescord, Forests Fisheries and Geomatic Sciences, University of Florida, lescord.g@ufl.edu
- Erik Emilson, Great Lakes Forestry Centre, Natural Resources Canada, erik.emilson@nrcan-rncan.gc.ca
date: "`r Sys.Date()`"
bibliography: [packages.bib, references.bib]
output: 
  bookdown::word_document2: default
---

<!--- Target journal, ES&T letters --->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8)
## Load libraries 
library(readxl)
library(lme4)
## install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(INLA)
library(effects)
library(sjPlot)
library(rstanarm)
library(tidyverse)
library(ggpubr)

## Write out package bibliography
knitr::write_bib(file = 'packages.bib')

# Select colours for consistent plots
cust_cols <- viridis::viridis_pal(end =0.8)(5)
names(cust_cols) <- c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")
```

# Abstract


Bigger fish are known to have higher concentrations of bioaccumulative contaminants like mercury (Hg). Sampling event regression (SERs) are frequently used to estimate size-adjusted concentrations of these contaminants in fish populations prior to making comparisons or further modeling. However, this approach can be limited by sample size constraints within and across waterbodies. Herein, we describe a mixed effects model approach that borrows strength from all available observations to estimate size-adjusted contaminant concentrations in individual fish populations and then compare amongst inference types and SERs. 

[Add sentence or two summarizing main results - accurate estimates with n = 2 fish, comparisons among approaches]. 

We recommend INLA as a reliable means of estimating size-adjusted contaminant concentration in fish populations, particularly when sample sizes are limited.  


# Key Words
Mercury, Arsenic, Fish, Mixed effects models, contaminant modelling


# Introduction


Consumption of wild-caught fish, while abundant with healthy fats and protein, is considered a potentially detrimental source of contaminants to the human body [@REF]. Bioaccumulative contaminants - which are incorporated into tissues faster than they can be excreted - are of particular concern because they can reach elevated levels in fish, even in remote waterbodies distant from primary sources of pollution. Due to their accumulation over time, the concentrations of these contaminants are often correlated with metrics of fish body size (e.g., weight, length). As a result, many monitoring programs and studies account for fish weight or length in their consumption recommendations (e.g., [@mecp2017]). This accumulation-size relationship is also accounted for in statistical models used in studies of contaminants (e.g., [@REF]) to avoid confounding effects of fish size. A common approach involved in modelling effect-contaminant relationships in fish is to determine the effects of various potential drivers on a size-adjusted estimate of the concentration of the contaminant across lakes (i.e., comparing effects on concentrations of the same size fish from each lake). A commonly used approach for estimating size-adjusted means of contaminant concentrations at the population-level is regressing contaminant concentrations against metrics of body size within a fish population (usually a unique species-lake combination for a given year) and use the resulting linear equation to estimate the concentration at a chosen size (e.g., 500 cm or 1kg); we refer to this approach as Sampling Event Regressions (SERs). 

The strength of fish contaminant-size relationships vary among different types of contaminants and across fish species or waterbodies, due to complex environmental and metabolic factors. For example, mercury (Hg) is a highly bioaccumulative contaminant that, due to its ubiquitous dispersion, is a global concern that is routinely monitored in fish. Mercury is well known to accumulate in the muscle tissue of fish, due its chemical speciation and inter-organ transport [@peng2017]. Many studies have found strong positive correlations between Hg concentrations ([Hg]) and body size in both freshwater [@REF] and marine [@REFS] environments and, thus, size-adjustments of Hg concentrations prior to making comparisons across environmental gradients are common [@REFs]. In contrast, arsenic is less bioaccumulative in fish, showing mixed and weaker relationships with metrics of body size [@lescord2020;@kluke2023]. Depending on its chemical speciation, arsenic can be a harmful carcinogenic contaminant, but it is less widely distributed and often originates from a localized point source of contamination or natural abundance. It is also less routinely monitored and researched when compared to [Hg] in fish, which results in less data to be available for size-adjustment models. However, not accounting for size in population-level comparisons of arsenic concentrations ([As]) could mean that some variation is unaccounted for, possibly weakening predictions and limiting our understanding of environmental cycling and bioaccumulation patterns.

In general, research and monitoring programs sample waterbodies for fish by collecting a targeted sample size (e.g., 10-20 individuals/species) across as broad of a size range as possible [@REFs]. However, such opportunistic sampling can limit the number of fish caught, the size range represented, or the distribution of fish sizes for a given population â€“ all of which may lead to over/under estimating standardized concentrations when using an SER approach [@REF]. Alternatively, deficient populations may be excluded altogether, sacrificing valuable data often from underrepresented waterbodies or fish species. Mixed effects regression approaches have been used to overcome this limitation such as maximum likelihood [@REF]. Bayesian linear mixed effects models [@REF] are also potential solution as they utilize all data across sampling structures (e.g., waterbodies) to inform predictions and allow for explicitly modeling variation of random effects variables. Different Bayesian linear mixed effects models have been implemented in R, including Bayesian inference in the \code(rstanarm) package [@REF], and approximate Bayesian inference in the \code(INLA) package [@REF]. 

Herein, we present a novel statistical approach to generating size-adjusted contaminant estimates at the population level using approximate Bayesian inference (INLA) and compare the results to SER, mixed effects regression (using the lmer package) and Bayesian inference (RSTAN). We evaluate these approaches using two contaminant measures, total [Hg] and [As] in fish muscle tissue, to assess differences in the modeling approaches based on bioaccumulative potential and data availability. More specifically, we compared the results of mixed model approaches that borrow strength from fish across all populations (i.e., pooled across waterbodies and through time) to generate predictions for individual sampling events on lakes to the SER approach. We hypothesize that mixed modelling approaches will provide comparable or more accurate predictions of contaminant concentrations to SER. We also expect that Bayesian approaches will have improved accuracy compared to more simplistic implementations of linear mixed models, especially for predictions in lakes with low sample numbers. We expect that INLA will outperform STAN models in terms of computation time, but have similar predictive accuracy.  


# Methods

## Datasets


We obtained fish-level Hg and As data for inland waterbodies across Ontario from the Ontario Ministry of Environment, Conservation, and Parks (OMECP). Although individual fish sampling protocols varied, muscle tissue sent to OMECP is analyzed using standardized methods as part of the Fish Contaminants Monitoring Program. More specifically, total [Hg] were measured using cold vapor-flameless atomic absorption spectroscopy (CV-FAAS) following protocol HGBIO-WS057 and total [As] was measured using Inductively Coupled Plasma Mass Spectrometry (ICP-MS) following method BIOTA-E3461. We limited our analyses to inland lakes and three species of interest: Salvelinus namaycush namaycush (common Lake Trout, hereafter LT), Esox lucius (Northern Pike, hereafter NP), and Sander vitreus (Walleye, hereafter WE). These three species represent important food fish in Ontario, sought by subsistence and sport fishers across the province. While they are all predatory fish, LT are generally restricted to profundal zones, while NP and WAL have broader movement patterns. In total, the final dataset we used included [Hg] in 37,923 fish and [As] in 1,001 fish. A full description of the data availability for each fish species and contaminant is in Table 1. We split the dataset into approximately 50/50 splits of test and train data using the \code(sample) function in R. A full description of the resulting train and testing datasets are in Table \@ref(tab:sampling-events-summary-train) and Table \@ref(tab:sampling-events-summary-test), respectively.


## Data Characterization

```{r hg-as-data}

### Units for both contaminants are ug/g wet weight
## Read in the mercury data
hg <- readxl::read_excel("./data/Ontario Inland 3 Species Hg 2008-2020-12-16.xlsx") %>% 
  ## filter data to only fish from lakes, produced by MECP, Walleye, Laketrout and Northern Pike and only ones that are from dorsal filet samples
  filter(SPECIES_NAME %in% c("Lake Trout", "Walleye", "Northern Pike"), 
         PORTION_TYPE_DESC %in% c("SKINLESS, BONELESS FILLET (STANDARD MOE DORSAL FILLET)", 
                     "SKINLESS, BONELESS FILLET PLUG (SKIN-OFF)")) %>% 
  mutate(CONTAMINANT = "Hg", WEIGHT_GRAM_LOG = log(WEIGHT_GRAM), LENGTH_CM_LOG = log(LENGTH_CM), 
         VALUE_LOG = log(VALUE)) %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, VALUE_LOG, LENGTH_CM, LENGTH_CM_LOG, WEIGHT_GRAM, WEIGHT_GRAM_LOG) %>% 
  filter(!is.na(LENGTH_CM_LOG), 
         !is.na(WEIGHT_GRAM_LOG))

## Read in the Arsenic data
As <- read.csv("./data/Fish_As_2021.12.01.csv")%>% 
  ## filter data to only fish from lakes, produced by MECP, Walleye, Laketrout and Northern Pike and only ones that are from dorsal filet samples
  filter(System_Type == "Lake",
         Data_source == "MECP", 
         Taxon %in% c("LT", "WALL", "NP"), 
         PORTION_TYPE_DESC %in% c("SKINLESS, BONELESS FILLET (STANDARD MOE DORSAL FILLET)", 
                     "SKINLESS, BONELESS FILLET PLUG (SKIN-OFF)")) %>% 
  mutate(VALUE = As_ug_ww, LENGTH_CM = TLEN/10, WEIGHT_GRAM = RWT,
         WEIGHT_GRAM_LOG = log(RWT), LENGTH_CM_LOG = log(LENGTH_CM), 
         VALUE_LOG = log(VALUE), WATERBODY_CODE = Waterbody, SPECIES_NAME = ifelse(Taxon=="NP", "Northern Pike", ifelse(Taxon == "WALL", "Walleye", "Lake Trout")), 
         SAMPLE_YEAR = as.factor(as.numeric(sapply(strsplit(Sampling_Date, split = "-"), function(x){x[[1]]}))),
         CONTAMINANT = "As") %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, VALUE_LOG, LENGTH_CM, LENGTH_CM_LOG, WEIGHT_GRAM, WEIGHT_GRAM_LOG) %>%
  filter(!is.na(LENGTH_CM_LOG), 
         !is.na(WEIGHT_GRAM_LOG))

## Set seed to make analysis repeatable
set.seed(434)

all_contaminants <- rbind(hg, As) %>%
  mutate(EVENT = paste(WATERBODY_CODE, SAMPLE_YEAR, sep = "_")) %>%
  ### Add a split for test/train data
  group_by() %>%
  mutate(test_train = !((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100))) %>%
  ## used rbinom to sample the fish in the targeted size range at a probability of 70% that they would be included in the test dataset.
  mutate(test_train = ifelse(!test_train, rbinom(sum(!test_train), 1, 0.5), test_train)) %>%
  mutate(VALUE_LOG_TEST = ifelse(!test_train, VALUE_LOG, NA), 
         VALUE_LOG_TRAIN = ifelse(test_train, VALUE_LOG, NA)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN)))


fish_amounts <- all_contaminants %>% group_by(CONTAMINANT) %>% summarize(total_fish = n())

ranges <- all_contaminants %>% 
  group_by(WATERBODY_CODE, SAMPLE_YEAR) %>% 
  summarize(range_wt_train = str_c(WEIGHT_GRAM[test_train == T], collapse = ", "), 
            range_wt_test = str_c(WEIGHT_GRAM[test_train == F], collapse = ", "),
            N_train = sum(test_train), 
            N_test = sum(!test_train),
            N_fish = n())
```

In total, the final dataset we used included [Hg] in `r fish_amounts$total_fish[fish_amounts$CONTAMINANT == "Hg"]` fish and [As] in `r fish_amounts$total_fish[fish_amounts$CONTAMINANT == "As"]` fish. Fish from the targeted weight classes were randomly sampled to create a test dataset with ~50% of the fish within 400 - 600g and 900 - 1100g and a train dataset with the remaining data from other fish size classes, as well as the remaining ~50% of fish in the targeted size classes (Tables \@ref(tab:sampling-events-summary-train), \@ref(tab:sampling-events-summary-test)) 


```{r sampling-events-summary-train}

all_contaminants %>% 
  filter(!is.na(VALUE_LOG_TRAIN)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  summarize(totalfish = n(),
            min_weights = min(WEIGHT_GRAM),
            max_weights = max(WEIGHT_GRAM)) %>%
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  summarize(`Total number of events` = n(), 
            `Events with more than one fish` = sum(totalfish > 1),
            `Events with at least 5 fish with proper weight range` = sum(totalfish > 4 & ((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000))),
            `Number of events excluded from SER` = sum(totalfish < 5 & !((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000))),
            `Number of lakes excluded from SER` = length(unique(WATERBODY_CODE[!WATERBODY_CODE %in% WATERBODY_CODE[totalfish > 4 & ((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000))]])), 
            #`Lakes excluded from SER` = str_c(unique(WATERBODY_CODE[!WATERBODY_CODE %in% WATERBODY_CODE[totalfish > 4]]), collapse = ", ")
            `Total number of unique lakes` = length(unique(WATERBODY_CODE))) %>% 
  knitr::kable(caption = "Summary of events (unique year and lake combinations) for each contaminant and species in the train dataset used in this analysis.")

```
 
 
 
```{r sampling-events-summary-test}

lakes_SER <- all_contaminants %>% 
  filter(!is.na(VALUE_LOG_TRAIN)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  summarize(totalfish = n(),
            min_weights = min(WEIGHT_GRAM),
            max_weights = max(WEIGHT_GRAM)) %>%
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  # exclude lakes with less than 5 fish, and also if they don't cover the range of the targets
  filter(totalfish>4 & ((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000))) %>%
  summarize(`Lakes in SER` = str_c(unique(WATERBODY_CODE), collapse = ", "))

all_contaminants %>% left_join(lakes_SER) %>%
  group_by(WATERBODY_CODE) %>% 
  mutate(SER_excluded = !grepl(unique(WATERBODY_CODE), `Lakes in SER`)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  mutate(totalfish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  filter(!is.na(VALUE_LOG_TEST)) %>%
  group_by(CONTAMINANT, SAMPLE_YEAR, WATERBODY_CODE, SPECIES_NAME) %>% 
  summarize(totalfish = unique(totalfish), SER_excluded = unique(SER_excluded)) %>% 
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  summarize(`Total number of events in prediction sample` = n(), 
            `Events modelled with more than one fish` = sum(totalfish > 1),
            `Events modelled with at least 5 fish` = sum(totalfish > 4),
            `Number of event predictions excluded from SER` = sum(SER_excluded),
            `Number of lakes predictions excluded from SER` = length(unique(WATERBODY_CODE[SER_excluded])), 
            #`Lakes excluded from SER` = str_c(unique(WATERBODY_CODE[!WATERBODY_CODE %in% WATERBODY_CODE[totalfish > 4]]), collapse = ", ")
            `Total number of unique lakes included in predictions` = length(unique(WATERBODY_CODE))) %>% 
  knitr::kable(caption = "Summary of events (unique year and lake combinations) for each contaminant and species in the test dataset used in this analysis.")

```
 
 
## Modelling


All modelling and analyses were performed in R Version 4.2.3 [@REF] on a Dell Latitude 5510 PC running Windows 10 Enterprise with a 1.70GHz, 2208 MHz 4 Core(s), 8 logical Processor, 16 GB of physical memory and 34.6 GB of virtual memory.


### Sampling event regressions


For each contaminant-species-waterbody-year combination (i.e., a sampling event), we developed log-contaminant (ug/g) by log-weight (g) regression models for those combinations with at least 5 sampled individuals, and only for models where there were values above and below at least one of our targeted weights for standardization [@4REFS]. Each model used a linear equation (Equation \@ref(eq:SER-eq).  


\begin{equation}
log(contaminant_i) = \beta_1 + \beta_2 * log(weight_i) + \epsilon_i (\#eq:SER-eq)
\end{equation}

$$
\epsilon_i \sim N(0, \sigma_i^2)
$$

where *i* is an individual fish for a species-waterbody-year combination; these models were run on training data until all combinations were exhausted. The time required to run each model was recorded, and we used these models to generate contaminant predictions and their 95% confidence intervals for 50g and 1000 g fish per sampling event, as well as predict contaminant concentrations of testing data. Predicted values of test data were collected and used to generate root mean squared error for each sampling event model (RMSE~event~), effectively representing the predictive accuracy of each model. 


```{r sampling-event-regressions, cache = TRUE}

#### Perform the Sampling Event regressions approach ####
#' This approach creates a separate linear regression for each 
#' lake - sampling year - species combination


## Create a function for performing a log weight - log contaminant model, taking a subset of the dataset as input. The function outputs resulting data and model statistics including R2's and RMSE.
SER_weight_function <- function(x){
  
  ## grab the weight percentile from the data
  percentile <- ecdf(x$WEIGHT_GRAM_LOG)
  
  ## calculate the regression for the sampling event
  tot.time <- system.time(rel <- lm(VALUE_LOG ~ WEIGHT_GRAM_LOG, data = x %>% filter(!is.na(VALUE_LOG_TRAIN))))
  
  ## grab some context and regression summary statistics
  n <- unique(x$N_fish) # number of individuals
  int <- formatC(rel$coefficients[1], digits = 4, format = "f") # estimated intercept
  slp <- formatC(rel$coefficients[2], digits = 4, format = "f") # estimated slope
  int_confint <- paste(formatC(confint(rel)[1, ], digits = 4, format = "f"),
                              collapse = " - ") # estimated intercept confidence interval
  slp_confint <- paste(formatC(confint(rel)[2, ], digits = 4, format = "f"),
                              collapse = " - ") # estimated slope confidence interval
  r2 <- formatC(summary(rel)$r.squared, digits = 4, format = "f") # adjusted R2
  
  ## calculate predicted values for the test data
  fits <- predict(rel, newdata = data.frame(WEIGHT_GRAM_LOG = x$WEIGHT_GRAM_LOG))
  
  ## calculate residuals of just train data for RMSE calculation
  RMSE_resid <- fits - x$VALUE_LOG
  RMSE <- sqrt(mean(RMSE_resid[!is.na(x$VALUE_LOG_TRAIN) & !is.na(RMSE_resid)]^2)) ### This will be used (and calculated for other approaches) to show model performance on lakes with different amounts of fishes - This is ALWAYS done with the test data
  
  resids <- resid(rel)
  
  
  ## Modify the predicted standardized weight too 1000 grams
  pred_modify <- c(1000, 500)
        
  target_size_percentile <- percentile(pred_modify)
        
  ## Generated exponentiated prediction interval
  pred <- exp(predict(rel,
                             newdata = data.frame(WEIGHT_GRAM_LOG= log(pred_modify)),
                             interval = "confidence"
        ))
  pred <- formatC(pred, digits = 4, format = "f")
        
        ## Bring context and summary statistics together into list
        frame <- list(n = n, int = int, int_confint = int_confint, slp = slp, slp_confint = slp_confint, r2 = r2, RMSE = RMSE,
                             target_size_percentile = target_size_percentile, pred = data.frame(pred, WEIGHT_GRAM = c(1000, 500)), data = cbind(x, fits = fits), 
                      run.time = tot.time)
  
}

### Create the series of models and exported results
if(!file.exists("out_workspaces/SER_models.RDS")){
SER_mods <- all_contaminants %>%
  # split the dataset by contaminant, species for each waterbody and sampling year
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$EVENT)) %>%
  discard(~ nrow(.x %>% filter(!is.na(VALUE_LOG_TRAIN))) == 0) %>%
  discard(~ nrow(.x %>% group_by() %>%
                   mutate(min_weights = min(WEIGHT_GRAM),
                          max_weights = max(WEIGHT_GRAM)) %>% 
                   ## Need to ensure the weights of the fish used to create the log-weight model span the weights we are going to standardize to
                   filter(!is.na(VALUE_LOG_TRAIN) & ((min_weights<500 & max_weights>500)|(min_weights<1000 & max_weights>1000)|(min_weights<500 & max_weights>1000)))) < 5) %>%
  map(~ SER_weight_function(.x))
save(SER_mods, file="out_workspaces/SER_models.RDS")
}else{
  load("out_workspaces/SER_models.RDS")
}


## compile the fitted data and input data
Modelled_data <- lapply(SER_mods, function(x){x$data %>% rename(SER_logfit = fits) %>% 
    # back calculate the fitted values to the un-logged values
    mutate(SER_fit = exp(SER_logfit))}) %>% 
  # compile as dataframe
  bind_rows() 

## Calculate accuracy of Contaminant predictions by this method
SER_accuracy_byN <- Modelled_data %>% filter(!is.na(VALUE_LOG_TEST)) %>% 
  mutate(SER_residuals = SER_fit - VALUE)

# pull the model accuracies (Mean squared errors) for the different models
SER_MSE <- lapply(SER_mods, function(x){data.frame(N_fish = x$n, RMSE = x$RMSE, R2 = x$r2, pred.lower = x$pred[1,2], pred.fit = x$pred[1,1], pred.upper = x$pred[1,3])}) %>% bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         WATERBODY_CODE = str_extract(str_extract(set, "[[:alnum:][:space:]_]+$"), "^[[:alnum:][:space:]]+")) %>%
  filter(WATERBODY_CODE %in% SER_accuracy_byN$WATERBODY_CODE) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    filter(keep)

## compile times for the SER models
SER_times <- lapply(SER_mods, function(x){x$run.time["elapsed"]}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = elapsed) %>%
  group_by(SPECIES_NAME, CONTAMINANT) %>%
  summarize(run.time = sum(run.time)) %>%
  mutate(method = "SER")

## Compile predicted sizes for 500g and 1000g fish with confidence intervals
predicted_data <- lapply(SER_mods, function(x){data.frame(N_fish = x$n, pred.lower = x$pred[,2], pred.fit = x$pred[,1], pred.upper = x$pred[,3], WEIGHT_GRAM = x$pred[,4])}) %>%
  bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         WATERBODY_CODE = str_extract(str_extract(set, "[[:alnum:][:space:]_]+$"), "^[[:alnum:][:space:]]+"), 
         SAMPLE_YEAR = str_extract(set, "[[:digit:]]+$"), 
         method = "SER") %>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method)

```


### Mixed effects regression models


For each contaminant-species combination, we developed log-contaminant (Î¼g/g) by log-weight (g) mixed effects regression models. We allowed for random variation in the slope and intercept per waterbody, and random variation in the intercept by sampling event (i.e., each unique waterbody-year combination). This identical model structure was fit in three modelling approaches: maximum likelihood inference in lme4 (ML models; cite XX), Bayesian inference with Markov Chain Monte Carlo in Stan through rstanarm (STAN models; cite XX) in R (cite XX), and approximate Bayesian inference using integrated nested Laplace approximation in INLA through R-INLA (INLA models; cite XX). These models used a random mixed effects formula (Equation \@ref(eq:MM-eq)).


\begin{equation}
log(contaminant_{ijk}) = \beta_1 + \beta_2 * log(weight_{ijk})+ U_{j} + W_{jk} + \epsilon_i (\#eq:MM-eq)
\end{equation}

$$
\epsilon_i \sim N(0, \sigma_i^2)
$$


Where *U* is the random effect on the slope for each waterbody, and *W* is the random effect of each waterbody-year sampling event.


For each modelling approach, the time required to run each model was recorded, and the residuals of the testing dataset were collected to calculate RMSE~event~ for the distinct sampling events in the dataset. We used these models to generate contaminant predictions and their 95% confidence intervals for 50g and 1000 g fish per sampling event. 


#### Maximum likelihood inference


ML models were fit using the \code(lme4) package, using default settings [@REF]. We generated results for the basic model, with the understanding that this model would not incorporate the uncertainty of the random effects. To account for this limitation, we also performed a bootstrapping analysis using \code(lme4)'s \code(bootMer) parametric bootstrapping with effects using 2000 simulations and with the use.u setting set to TRUE using 4 cpus. We used the bootstrapping results to generate 95% confidence intervals of the ML coefficients and predictions that would include the uncertainty in the random effects.


```{r lmer-mixedmod, cache = T}
### Perform the Lmer-mixed model Maximum likelihood approach.

## Make some functions for easier processing

# Function to bootstrap values
LMER_boot_est <- function(.) {
  c(beta=fixef(.), 
    as.data.frame(VarCorr(.))$sdcor[c(1:3,5)])
}

## function to grab summary of bootstrapping results
LMER_boot_est_summary <- function(merBoot){
  
  t <- as.data.frame(merBoot$t)
  
  names(t) <- c("Intercept", "Slope", "WATERBODY_CODE_SAMPLE_YEAR", 
                "WATERBODY_CODE", "WATERBODY_CODE_SLOPE", "RESIDUAL")
  
  est = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.5, na.rm = T)))
  upr = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.975, na.rm = T)))
  lwr = apply(t, 2, function(x) as.numeric(quantile(x, probs = 0.025, na.rm = T)))
  
  ret_tab <- as.data.frame(dplyr::bind_rows(est, lwr, upr))
  rownames(ret_tab) <- c("Estimate", "Lower", "Upper")  
  
  return(ret_tab)  
}

## function to grab summary of predicted values
LMER_boot_pred_summary <- function(merBoot) {
  return(
    data.frame(fit = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.5, na.rm=TRUE))),
               lwr = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE))),
               upr = apply(merBoot$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
    )
  )
}

## Function to create bootstrapped predictions
LMER_boot_initiate <- function(varlist, nclust, envir){
  closeAllConnections()
  clust <- parallel::makeCluster(nclust)
  parallel::clusterEvalQ(clust, library("lme4"))
  parallel::clusterExport(cl = clust, varlist = varlist, envir = envir)
  showConnections()
  clust
}


lmer_bootstrap_prep <- function(x){
  ## Generate prediction for each waterbody
  prediction.data <- x %>% 
    filter(!is.na(VALUE_LOG_TRAIN)) %>% 
    dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
    distinct() %>% mutate(WEIGHT_GRAM_LOG = log(1000)) %>% 
    rbind( x %>% 
             filter(!is.na(VALUE_LOG_TRAIN)) %>% 
             dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, EVENT) %>% 
             distinct() %>% mutate(WEIGHT_GRAM_LOG = log(500)) )
  
  return(list(data = x, preddata = prediction.data))
}

## Function to create initial LMER model using a subset of dataframe
lmer_mass_model <- function(x){
  
  lmer.time <- system.time(mod.lmer <- lmer(VALUE_LOG ~ WEIGHT_GRAM_LOG + (WEIGHT_GRAM_LOG|WATERBODY_CODE) + (1|EVENT), data = x$data[!is.na(x$data$VALUE_LOG_TRAIN), ]))
  
  ## Data for fit/accuracy plotting
  data.out <- x$data %>%
    cbind(LMER_logfit = predict(mod.lmer, newdata = x$data, allow.new.levels = TRUE)) %>% 
    mutate(LMER_resid = LMER_logfit - VALUE_LOG,
           LMER_fit = exp(LMER_logfit))
  
  prediction_data <- x$preddata
  ## get the Bootstrap confidence intervals from bootMer
  clust <- LMER_boot_initiate(varlist = "prediction_data", nclust = 10, envir = environment()) 
  lmer.time <- system.time(LMER_MASS_boot_est <- lme4::bootMer(mod.lmer, LMER_boot_est, 
                                                      nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                      parallel = "snow", 
                                                      cl = clust, 
                                                      ncpus = 4))
  
  ## Get fitted values from bootstrapping
  LMER_MASS_fit_pred <- function(., newdata) {
      predict(., newdata = x$data, allow.new.levels = TRUE)
  }
  
  
  boot.time <- system.time(LMER_MASS_boot_fit <- lme4::bootMer(mod.lmer, LMER_MASS_fit_pred, 
                                                      nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                      parallel = "snow", 
                                                      cl = clust, 
                                                      ncpus = 4))

  
  ## Function for bootstrapped predictions ## specific for each iteration
   LMER_MASS_boot_pred <- function(., newdata) {
      predict(., newdata=x$preddata)
   }
   
   system.time(LMER_MASS_boot_pred_res <- lme4::bootMer(mod.lmer, LMER_MASS_boot_pred, 
                                                           nsim=2000, use.u = TRUE, .progress = "txt",  ## 99 before
                                                           parallel = "snow", 
                                                           cl = clust, 
                                                           ncpus = 4)) 
   
   results = list(data = data.out, 
                  bootstrapped.fits = LMER_boot_pred_summary(LMER_MASS_boot_fit), 
                  estimates = LMER_boot_est_summary(LMER_MASS_boot_est),
                  predict = cbind(predict(mod.lmer, newdata=x$preddata), x$preddata), 
                  predicted.1000g = cbind(LMER_boot_pred_summary(LMER_MASS_boot_pred_res), x$preddata), 
                  run.time.lmer = lmer.time,
                  run.time.boot.lmer = boot.time)
}

#### Modelling as separate models by Contaminant ####
if(!file.exists("out_workspaces/LMER_models.RDS")){
  ## Produce individual models for each contaminant/species combination
LMER_data <- all_contaminants %>% 
  split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
  map(~ lmer_bootstrap_prep(.x)) %>% 
  map(~ lmer_mass_model(.x))
  ## Cache this dataset, because TAKES FOREVER
  save(LMER_data, file = "out_workspaces/LMER_models.RDS")
} else {
  load("out_workspaces/LMER_models.RDS")
}

LMER_bootstraps_data <- LMER_data %>% 
  map(~ cbind(.x$data, .x$bootstrapped.fits)) %>% 
  bind_rows() %>% 
  mutate(boot_log_resid = fit - VALUE_LOG) %>% 
  rename(boot_log_fit = fit, boot_log_lwr = lwr, boot_log_upr = upr, LMER_log_resid = LMER_resid) %>%
  mutate(boot_resid = exp(boot_log_fit) - VALUE, 
         LMER_resid = LMER_fit - VALUE)


## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
Boot_LMER_data_by_N <- LMER_bootstraps_data %>% 
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(boot_LMER_RMSE = sqrt(mean(boot_log_resid[!is.na(VALUE_LOG_TEST)]^2)), LMER_RMSE=sqrt(mean(LMER_log_resid[!is.na(VALUE_LOG_TEST)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
    mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    filter(keep) 

  models_accuracy_by_N <- Boot_LMER_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, LMER_logfit, LMER_log_resid, LMER_resid, boot_log_fit, boot_log_resid, boot_resid, N_fish) %>%
    pivot_longer(cols = c(LMER_logfit, LMER_log_resid, LMER_resid, boot_log_fit, boot_log_resid, boot_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(SER_accuracy_byN %>% pivot_longer(cols=c(SER_logfit, SER_fit, SER_residuals), names_to = "response", values_to = "predicted_value"))


models_RMSE <- Boot_LMER_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, boot_LMER_RMSE, LMER_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(boot_LMER_RMSE, LMER_RMSE), names_to = "response", values_to = "predicted_value")

models_RMSE <- models_RMSE %>% rbind(SER_MSE %>% rename(predicted_value = RMSE) %>% mutate(response = "SER_RMSE"))

## Compile Run Times
LMER_times <- lapply(LMER_data, function(x){data.frame(V1 = c(x$run.time.lmer["elapsed"], x$run.time.boot.lmer["elapsed"]), method = c("LMER", "Boot.LMER"))}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

### Compare the results of predicted 1000 g fish
predicted_data <- rbind(predicted_data, LMER_data %>% 
  map(~ rbind(cbind(data.frame(.x$predicted.1000g), WEIGHT_GRAM=c(1000, 500), method = "boot_LMER"), 
              cbind(data.frame(.x$predicted), WEIGHT_GRAM=c(1000, 500), method = "LMER"))) %>% 
  bind_rows(.id = "set") %>% 
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(fit), pred.lower = exp(lwr), 
         pred.upper = exp(upr), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


#### Bayesian inference with Markov Chain Monte Carlo


For STAN models, all models were run with chains and cores set to 4. We ran the models for [Hg] datasets using the RSTAN default settings. [As] were lower sample size, and so required higher iterations to achieve reliable model results, these were run with 9000 iterations and an adapt_delta setting of 0.99, this essentially makes acceptance criteria for posterior distributions during the adaptation period more strict, and lowers the step-size of the model, while increasing the computation time. The 50th percentile of predicted values were used to calculate residuals, RMSE~event~ and RMSE~global~ for these models.


```{r RSTAN-models, cache = T}
## Set up RSTAN function to run on data subsets

contam.RSTAN <- function(x){
  
  ## Print out the model for troubleshooting purposes
  message(str_c(unique(x %>% select(SPECIES_NAME, CONTAMINANT)), collapse = " "))
  
  ## Add some Lake Data For predictions
  
  pred.data <- x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(1000)) %>% 
    select(WEIGHT_GRAM_LOG, WATERBODY_CODE, EVENT, SPECIES_NAME, CONTAMINANT) %>%
    distinct() %>% rbind(x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 500, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(500)) %>% 
    select(WEIGHT_GRAM_LOG, WATERBODY_CODE, EVENT, SPECIES_NAME, CONTAMINANT) %>%
    distinct())
  
  ## Grab the time it took to run the overall model using system.time ##
  
  ## Provide more iterations for Arsenic datasets that have fewer data points
  if(nrow(x) < 500){
    iterations = 9000; adapt_delta = 0.99
    }else{
    iterations = 2000; adapt_delta = 0.8}
  
  tot.time <- system.time(RSTAN_MASS <- stan_glmer(VALUE_LOG ~WEIGHT_GRAM_LOG+ (WEIGHT_GRAM_LOG|WATERBODY_CODE) + (1|EVENT),
                     data = x[!is.na(x$VALUE_LOG_TRAIN), ], 
                     cores=4, chains = 4, iter = iterations, adapt_delta = adapt_delta)) ## required some playing around with the iterations, default of 2000 was NOT enough for the As datasets, and was overkill for the large Hg datasets.
  
  fitted.data <- rstanarm::posterior_predict(RSTAN_MASS,
                                                        newdata = x[is.na(x$VALUE_LOG_TRAIN),]
)
  fitted.data <- x[is.na(x$VALUE_LOG_TRAIN),] %>% 
    cbind(t(apply(fitted.data, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}))) %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`) %>%
    mutate(resid_log_rstan = VALUE_LOG - RSTAN_posterior_q50, 
           resid_rstan = exp(VALUE_LOG) - exp(RSTAN_posterior_q50))
  ## Get predicted data for 1000g fishes
  
  RSTAN_MASS_predictions <- rstanarm::posterior_predict(RSTAN_MASS,
                                                        newdata = pred.data
)
  RSTAN_MASS_predictions <- pred.data %>% 
    cbind(t(apply(RSTAN_MASS_predictions, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}))) %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`)
  ## Compile model effects ranges
  
  estimates <- as.data.frame(as.matrix(RSTAN_MASS))
  estimates <- apply(estimates, 2, function(x){quantile(x, probs = c(0.025, 0.5, 0.975))}) %>% t() %>% as.data.frame() %>% 
    rename(RSTAN_posterior_q2p5 = `2.5%`, 
           RSTAN_posterior_q50 = `50%`,
           RSTAN_posterior_q97p5 = `97.5%`) %>% 
    rownames_to_column("parameter")
  
  ## Compile results
  results = list(data = x[!is.na(x$VALUE_LOG_TRAIN), ] %>% cbind(resid_log_rstan = resid(RSTAN_MASS)), 
                 fits = fitted.data, 
                 estimates = estimates,
                 predicted.1000g = RSTAN_MASS_predictions, 
                 run.time = tot.time)
}



if(!file.exists("out_workspaces/RSTAN_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  RSTAN_data <- all_contaminants %>% 
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
  map(~ contam.RSTAN(.x))
  ## Cache this dataset, because TAKES FOREVER
  save(RSTAN_data, file = "out_workspaces/RSTAN_models.RDS")
} else {
  load("out_workspaces/RSTAN_models.RDS")
}

RSTAN_data_by_N <- RSTAN_data %>% 
  map(~ rbind(.x$data, .x$fits)) %>% 
  bind_rows() %>% 
  rename(RSTAN_log_fit = RSTAN_posterior_q50, RSTAN_log_lwr = RSTAN_posterior_q2p5, RSTAN_log_upr = RSTAN_posterior_q97p5, RSTAN_log_resid = resid_log_rstan, RSTAN_resid = resid_rstan) %>% 
  ## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(RSTAN_RMSE = sqrt(mean(RSTAN_log_resid[!is.na(VALUE_LOG_TRAIN)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
    mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    filter(keep) 

## Get distinct individual residuals compiled and added to other model results

models_accuracy_by_N <- RSTAN_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, RSTAN_log_fit, RSTAN_log_resid, RSTAN_resid, N_fish) %>%
    pivot_longer(cols = c(RSTAN_log_fit, RSTAN_log_resid, RSTAN_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(models_accuracy_by_N)

## Get data from overall model fits compiled and added to other model results

models_RMSE <- RSTAN_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, RSTAN_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(RSTAN_RMSE), names_to = "response", values_to = "predicted_value") %>% 
  rbind(models_RMSE)

## Compile Run Times
RSTAN_times <- lapply(RSTAN_data, function(x){data.frame(V1 = c(x$run.time["elapsed"]), method = "RSTAN")}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

## RSTAN predicted data for 1000 and 500 
predicted_data <- rbind(predicted_data, RSTAN_data %>% 
  map(~ cbind(data.frame(.x$predicted.1000g), method = "RSTAN")) %>% 
  bind_rows(.id = "set") %>% 
  mutate(WEIGHT_GRAM = round(exp(WEIGHT_GRAM_LOG),0), 
         SAMPLE_YEAR = str_extract(EVENT, "[[:digit:]]+$"),
         CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(RSTAN_posterior_q50), pred.lower = exp(RSTAN_posterior_q2p5), 
         pred.upper = exp(RSTAN_posterior_q97p5), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


#### Approximate Bayesian inference using integrated nested Laplace approximation


INLA models were run with precision of priors set to 0.001, and the formula structure was entered for the "iid2d" model to account for the covariance of the random effects due to waterbody. The 50th percentile of predicted values were used to calculate residuals, RMSE~event~ and RMSE~global~ for these models. 


```{r INLA-models, cache = T}

## ## Set up precision --> standard deviation formula; Bayesian models use precision (tau) where sd = 1/sqrt(tau) 
MySqrt <- function(x) {
  1 / sqrt(x)
}

## Set up INLA function to run on data subsets

contam.INLA <- function(x){
  
  # Set prior on precision
  prec.prior <- list(prec = list(param = c(0.001, 0.001)))
  
  ## Add some Lake Data For predictions
  
  pred.data <- x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(1000)) %>% 
    distinct() %>% rbind(
      x %>% 
    mutate(VALUE = NA, 
           VALUE_LOG = NA, 
           LENGTH_CM = NA, 
           LENGTH_CM_LOG = NA, 
           WEIGHT_GRAM = 1000, 
           VALUE_LOG_TEST = NA, 
           VALUE_LOG_TRAIN = NA, 
           test_train = FALSE,
           WEIGHT_GRAM_LOG = log(500)) %>% 
    distinct()
    )
  
  x <- x %>% rbind(pred.data)
  
  ## Grab the time it took to run the overall model using system.time ##
  
  ## Add dummy variable for the random effects
  
  tot.time <- system.time(INLA_MASS <- inla(VALUE_LOG_TRAIN ~WEIGHT_GRAM_LOG+ 
                      #' The next two lines code for the random slopes effect due to waterbody, - basically codes for the random effect of the 
                      #' two variables, expecting covariance of these variables  
                      #' See the documentation for the description of this implementation 'inla.doc("iid2d")'
                       f(WATERBODY_CODE1, n = 2*unique(x$n_waterbody), model = "iid2d") + 
                       f(WATERBODY_CODE2, WEIGHT_GRAM_LOG, copy = "WATERBODY_CODE1") + 
                       f(EVENT, model = "iid"),
                     data = x, 
                     control.predictor = list(
                       compute = TRUE, 
                       quantiles = c(0.025, 0.5, 0.975)
                     ),
                     control.compute = list(
                       cpo = TRUE
                     )
                    ))
  
  fitted.data <- data.frame(WATERBODY_CODE = x$WATERBODY_CODE,
                       SAMPLE_YEAR = x$SAMPLE_YEAR, 
                       SPECIES_NAME = x$SPECIES_NAME,
                       CONTAMINANT = x$CONTAMINANT, 
                       VALUE = x$VALUE, 
                       VALUE_LOG = x$VALUE_LOG,
                       WEIGHT_GRAM = x$WEIGHT_GRAM, 
                       WEIGHT_GRAM_LOG = x$WEIGHT_GRAM_LOG,
                       TEST.val = !is.na(x$VALUE_LOG_TEST), 
                       INLA_posterior_q50 = INLA_MASS$summary.fitted.values[, "0.5quant"], 
                       INLA_posterior_q2p5 = INLA_MASS$summary.fitted.values[, "0.025quant"], 
                       INLA_posterior_q97p5 = INLA_MASS$summary.fitted.values[, "0.975quant"]) %>% 
    mutate(resid_log_inla = VALUE_LOG - INLA_posterior_q50, 
           resid_inla = exp(VALUE_LOG) - exp(INLA_posterior_q50))
  
  ## Compile model effects ranges
  fixed.effect <- INLA_MASS$summary.fixed
  fixed.effect$Type <- "Fixed"
  
  random.effect.lake <- INLA_MASS$summary.random$WATERBODY_CODE1
  random.effect.lake$ID <- as.character(random.effect.lake$ID)
  random.effect.lake$WATERBODY_CODE1 <- random.effect.lake$ID
  random.effect.lake <- merge(random.effect.lake, distinct(x[,c("WATERBODY_CODE1", "WATERBODY_CODE")]), no.dups = T)
  random.effect.lake <- random.effect.lake[!duplicated(random.effect.lake), ]
  random.effect.lake$Type <- "Random Intercept - Waterbody"
  
  random.slope.lake <- INLA_MASS$summary.random$WATERBODY_CODE2
  random.slope.lake$ID <- as.character(random.slope.lake$ID)
  random.slope.lake$WATERBODY_CODE2 <- random.slope.lake$ID
  random.slope.lake <- merge(random.slope.lake, distinct(x[,c("WATERBODY_CODE2", "WATERBODY_CODE")]), no.dups = T)
  random.slope.lake <- random.slope.lake[!duplicated(random.slope.lake), ]
  random.slope.lake$Type <- "Random Slope - Waterbody"
  
  random.effect.event <- INLA_MASS$summary.random$EVENT
  random.effect.event$ID <- as.character(random.effect.event$ID)
  random.effect.event$EVENT <- random.effect.event$ID
  random.effect.event <- random.effect.event[!duplicated(random.effect.event), ]
  random.effect.event$Type <- "Random Slope - Waterbody Sampling Year"
  
  estimates <- list(fixed.effect = fixed.effect, random.effect.lake = random.effect.lake, 
                    random.slope.lake = random.slope.lake, random.effect.event = random.effect.event)
  ## Compile results
  results = list(data = fitted.data[!fitted.data$TEST.val & !is.na(fitted.data$VALUE), ], 
                 fits = fitted.data[fitted.data$TEST.val & !is.na(fitted.data$VALUE), ], 
                 estimates = estimates,
                 predicted.1000g = fitted.data[is.na(fitted.data$VALUE), ], 
                 run.time = tot.time)
}


if(!file.exists("out_workspaces/INLA_models.RDS")){
  ## Produce individual models for each contaminant/species combination
  
  INLA_data <- all_contaminants %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(WATERBODY_CODE1 = as.integer(as.factor(WATERBODY_CODE))) %>% # for inla model, this needs to be an integer
    mutate(WATERBODY_CODE2 = WATERBODY_CODE1 + max(WATERBODY_CODE1)) %>% # for inla model, this needs to be a different set of integers
    mutate(n_waterbody = n_distinct(WATERBODY_CODE)) %>% # for inla model, we need to have a number of lakes assigned for setting the appropriate attributes for a two-dimensional model
    split(list(.$CONTAMINANT, .$SPECIES_NAME)) %>%
    map(~ contam.INLA(.x))
  ## Cache this dataset, because TAKES FOREVER
    save(INLA_data, file = "out_workspaces/INLA_models.RDS")
} else {
  load("out_workspaces/INLA_models.RDS")
}

## Summarize data by event
INLA_data_by_N <- INLA_data %>% 
  map(~ rbind(.x$data %>% mutate(VALUE_LOG_TRAIN = VALUE_LOG, VALUE_LOG_TEST = NA), .x$fits %>% mutate(VALUE_LOG_TRAIN = NA, VALUE_LOG_TEST = VALUE_LOG))) %>% 
  bind_rows() %>% 
  rename(INLA_log_fit = INLA_posterior_q50, INLA_log_lwr = INLA_posterior_q2p5, INLA_log_upr = INLA_posterior_q97p5, INLA_log_resid = resid_log_inla, INLA_resid = resid_inla) %>% 
  ## ## Calculate accuracy of Contaminant predictions by this method as well as model accuracies using RMSE
  group_by(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT) %>% 
  mutate(N_fish = sum(!is.na(VALUE_LOG_TRAIN))) %>%
  # calculate RMSE on train data
  mutate(INLA_RMSE = sqrt(mean(INLA_log_resid[!is.na(VALUE_LOG_TRAIN)]^2))) %>% 
  filter(!is.na(VALUE_LOG_TEST)) %>%
  ## Compare similar sample sizes from each N_fish category - lowest 25th percentile
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    mutate(sample_num = n()) %>% 
    group_by(CONTAMINANT, SPECIES_NAME) %>%
    mutate(sampling_num = as.integer(quantile(sample_num, 0.25)), 
           n_samps = as.integer(sample_num - sampling_num)) %>%
  group_by(CONTAMINANT, SPECIES_NAME, N_fish) %>% 
    # this filters the samples to a random sample of lakes with the 25th percentile of representative sample lakes, so that the graphing comparison of boxplots is less biased by unbalanced sample numbers
    mutate(keep = ifelse(sampling_num < sample_num, sample(c(rep(FALSE, times = unique(n_samps)), rep(TRUE, times = unique(sampling_num))), unique(sample_num)), TRUE)) %>% 
    filter(keep) 

## Get distinct individual residuals compiled and added to other model results

models_accuracy_by_N <- INLA_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, VALUE, WEIGHT_GRAM, VALUE_LOG, WEIGHT_GRAM_LOG, INLA_log_fit, INLA_log_resid, INLA_resid, N_fish) %>%
    pivot_longer(cols = c(INLA_log_fit, INLA_log_resid, INLA_resid), names_to = "response", values_to = "predicted_value") %>% 
    rbind(models_accuracy_by_N)

## Get data from overall model fits compiled and added to other model results

models_RMSE <- INLA_data_by_N %>% 
  dplyr::select(WATERBODY_CODE, SAMPLE_YEAR, SPECIES_NAME, CONTAMINANT, N_fish, INLA_RMSE) %>% 
  distinct() %>%
  pivot_longer(cols = c(INLA_RMSE), names_to = "response", values_to = "predicted_value") %>% 
  rbind(models_RMSE)

## Compile Run Times
INLA_times <- lapply(INLA_data, function(x){data.frame(V1 = c(x$run.time["elapsed"]), method = "INLA")}) %>% 
  # compile as dataframe
  bind_rows(.id = "ID") %>% as.data.frame() %>% 
  mutate(SPECIES_NAME = str_extract(ID, "Walleye|Lake Trout|Northern Pike"),
         CONTAMINANT = str_extract(ID, "^Hg|^As"),
         run.time = V1) %>%
  group_by(SPECIES_NAME, CONTAMINANT, method) %>%
  summarize(run.time = sum(run.time))

## INLA predicted data for 1000 and 500 
predicted_data <- rbind(predicted_data, INLA_data %>% 
  map(~ cbind(data.frame(.x$predicted.1000g), method = "INLA")) %>% 
  bind_rows(.id = "set") %>% 
  mutate(WEIGHT_GRAM = round(exp(WEIGHT_GRAM_LOG),0), 
         CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         pred.fit = exp(INLA_posterior_q50), pred.lower = exp(INLA_posterior_q2p5), 
         pred.upper = exp(INLA_posterior_q97p5), N_fish = NA)%>%
  dplyr::select(N_fish, pred.lower, pred.fit, pred.upper, WEIGHT_GRAM, CONTAMINANT, SPECIES_NAME, WATERBODY_CODE, SAMPLE_YEAR, method))
```


## Comparing accuracy of predictions across model types


We compared model residuals of fish in 500 g and 1000 g size ranges (as calculated by the actual test values subtracted from the predicted values) to visualize the range in predictive error for each approach. The RMSE~event~ for each of the modelling approaches, as well as the RMSE~global~ of each model against the runtime required for each approach was based off the fit of each model to the training data. We also compared predicted values for 500g and 1000g fish for each sampling event in the dataset. We used the wilcox.test function R  to perform wilcoxon two-sided tests to evaluate the deviation of residuals from zero, and we compared predicted values to true values, and SER predicted values with the lm function in R, and visually assessed the overlap of the linear relationships with a 1:1 relationship with 25% error. 


# Results


## Model implementation 


Application of each approach varied in difficulty, going from LMER<SER<STAN<INLA. The LMER approach was simple enough that any beginner R user could implement it quickly, without requiring knowledge of loops or other programming. The SER approach required more programming knowledge in order to implement it efficiently, and a significant amount of pre-screening of data to ensure that data used for linear models covered a large enough span to develop a curve. There were more documentation and reading requirements to implement the RSTAN and INLA models. There is a higher risk of incorrect implementation of INLA models with the current INLA package implementation, since the model formula input deviates from the typical R notation. There is thorough documentation of the model notation in the INLA package, but it is nonetheless a consideration in the implementation of this approach, as it added complexity when assessing the nested random effect of waterbody and sampling event. The [As] models were generally more difficult to fit due to lower sample sizes, requiring different settings, while [Hg] models ran well on the default settings of the lmer, rstan and inla functions. 


## Data biases

```{r biases, include=FALSE}
all_contaminants %>% group_by(SPECIES_NAME, CONTAMINANT) %>% summarize(weight.p95= quantile(WEIGHT_GRAM,.90), val.p95 = quantile(VALUE,.90))
```

The dataset was heavily biased to smaller fish, but had a normal distribution of values around the targeted weights, which were highly represented in the data (Supplemental Fig \@ref(fig:weight-values)). Generally, the dataset was dominated by low levels of contaminant, less than 1.3 ug/gram~wet weight~ [Hg] and less than 0.4 ug/g~wet weight~ [As] (Supplemental Fig \@ref(fig:response-values)). 


## Prediction results

```{r predictions, fig.height=10, fig.width = 8, fig.cap = "Predicted concentration of [As] and [Hg] in fish tissue of 400-600g and 900-1100g fish compared to known values. Points display each individual fish prediction and a solid red line shows a 1-1 relationship. Dashed red lines provide an interval for predicted values that are within 25% of the predicted SER value. A general lm model is also displayed to better represent overall trends."}
#Plot comparison of predicted Hg and As content of 500g and 1000g fish for each technique against The SER value
## fill in missing N_fish information
predicted_data <- predicted_data %>% group_by(SAMPLE_YEAR, SPECIES_NAME, WATERBODY_CODE, CONTAMINANT) %>% 
  mutate(N_fish = ifelse(sum(is.na(N_fish)) == n(), 0, unique(N_fish[N_fish>0]))) %>% group_by() %>%
  mutate(pred.lower = as.numeric(pred.lower), 
         pred.upper = as.numeric(pred.upper), 
         pred.fit = as.numeric(pred.fit), 
         N_fish = ifelse(is.na(N_fish), 0, N_fish)) %>%
  mutate(method = factor(method, levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))) %>% 
  filter(!N_fish == 0)

## prepare for plotting against SER predictions
pred.plot <- predicted_data %>% pivot_wider(id_cols = c("N_fish", "SAMPLE_YEAR", "SPECIES_NAME", "WATERBODY_CODE", "CONTAMINANT", "WEIGHT_GRAM"), names_from = method, values_from = pred.fit, values_fn = mean) %>%
  pivot_longer(cols = c(RSTAN, INLA, LMER, boot_LMER), values_to = "pred.fit", names_to = "method")%>%
  mutate(method = factor(method, levels = c("LMER", "boot_LMER", "RSTAN", "INLA")))
  
## Lm summaries
lm_sums <- pred.plot %>% 
  group_by(CONTAMINANT) %>%
  mutate(text.x = max(SER)* 0.3, text.y = max(pred.fit, na.rm = T)*0.85) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$method)) %>%
    map(~ list(mod = lm(pred.fit~SER, data =.x), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(R2 = round(summary(.x$mod)$adj.r.squared, 2), 
                     intercept = round(.x$mod$coef[[1]], 2),
                     slope = round(.x$mod$coef[[2]], 2),
                     p = round(summary(.x$mod)$coef[2,4], 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         method = factor(str_extract(set, "SER|boot_LMER|LMER|RSTAN|INLA"), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")),
         R2.text = paste0("Slope = ", slope, "\nIntercept = ", intercept  ,"\nR2 = ",R2))


## plots for each size prediction  
plot1 <- ggplot(pred.plot %>% filter(CONTAMINANT == "As"), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
    geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  facet_grid(CONTAMINANT+SPECIES_NAME~method)+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

plot2 <- ggplot(pred.plot %>% filter(CONTAMINANT == "Hg"), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
    geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  facet_grid(CONTAMINANT+SPECIES_NAME~method)+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```


Predictions from LMER and LMER-bootstrapped approaches were consistent with each other, and had a general association with predicted values from SER, but much more noise in the predictions than the RSTAN or INLA approaches. The RSTAN and INLA approaches both had predicted values that performed very comparably with SER predictions, with most values greater than 1 ug/g~wet weight~ falling within 25% of the predicted SER values. The values lower than 1 ug/g~wet weight~ had more variance than this, but stayed within approximately 0.5 ug/g~wet weight~(Fig \@ref(fig:predictions)). Additional graphing of these predictions revealed that much of the deviations in these predictions were from predictions of the 1000g weights, and the 500g weight predictions had stronger associations (Supplemental Figs \@ref(fig:pred-500g), \@ref(fig:pred-1000g)).


## Model performance by sampling event


```{r RMSE-N, fig.width = 10, fig.height = 7,  fig.cap= "Residual mean squared error of models from sampling events trained with different numbers of fish. RMSE of training set sampling events are compared to the number of fish used from the sampling event that were included in the training dataset. For each N, a boxplot displays the 25th and 75th percentiles and the median RMSE, with the whiskers extending out to 1.5 x the interquartile range. A line is plotted across the median values to show the overall trend in the values."}
# plot model accuracies against number of fish used to produce the model
ggplot(models_RMSE %>% 
         mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))),
       aes(N_fish, predicted_value, color = response)) +
  geom_boxplot(aes(group = paste(N_fish, response)), alpha = 0.2) + 
  geom_line(data = models_RMSE %>% 
         mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))) %>%
              group_by(SPECIES_NAME, CONTAMINANT, N_fish, response)%>% 
              summarize(predicted_value = median(predicted_value))
            ) +
  facet_grid(response~CONTAMINANT+SPECIES_NAME , scales = "free_x") + ylab("RMSE") + xlab("Number of Fish used from sampling event used in model training") + theme_minimal()+
  scale_color_manual(values = cust_cols)


```


All approaches had RMSE for events that generally increased and stabilized at about 6 fish sampling events. LMER and LMER bootstrapped approaches had the highest RMSE ranges in [Hg] datasets (`r str_c(round(range((models_RMSE %>% mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")))%>% filter(CONTAMINANT == "Hg" & response %in% c("LMER", "boot_LMER")))$predicted_value, na.rm = T), 2), collapse = " - ")`) while SER, RSTAN and INLA approaches had comparable fits, with a lower range of RMSE~event~ that were more consistently between `r str_c(round(range((models_RMSE %>% mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")))%>% filter(CONTAMINANT == "Hg" & !response %in% c("LMER", "boot_LMER")))$predicted_value, na.rm = T), 2), collapse = " - ")` RMSE. There was some additional noise, and higher RMSE~event~ for [Hg] and [As] models in compared to the SER approach, but much of that was in the lower N lakes. RMSE for As models were more consistent between approaches with a range of `r str_c(round(range((models_RMSE %>% mutate(response = factor(gsub("_RMSE", "", response), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")))%>% filter(CONTAMINANT == "As"))$predicted_value, na.rm = T), 2), collapse = " - ")` RMSE~event~ (Fig \@ref(fig:RMSE-N)). 


## Error distribution amongst models

```{r resids-fishsize, fig.height = 8, fig.cap="Residuals for fish from events modelled with at least 5 fish, within 100 g of the targeted prediction weights (500g and 1000g) from each modelling approach in the study. Values are displayed in boxplots where the edges of the box represent the 25th and 75th percentiles and the central line the median, with the whiskers extending out to 1.5 x the interquartile range. A red horizontal line on each plot indicates where there is a residual of zero. '*' are used to represent medians that significnatly deviate from zero based on two sided wilcoxon tests."}

## wilcoxon one-sided tests to see if residuals deviate from zero
wilcox.sig <- models_accuracy_by_N %>%
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)) %>%
         mutate(weight_group = ifelse(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600, "400 - 600", "900-1100")) %>%
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         filter(N_fish >= 5) %>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))) %>%
  group_by(CONTAMINANT, SPECIES_NAME) %>%
  mutate(max.x = max(predicted_value)*1.15) %>%
  group_by(weight_group, response, CONTAMINANT, SPECIES_NAME) %>%
  summarise(sig.result = ifelse(wilcox.test(predicted_value)$p.value < 0.05, "*", ""), 
            max.x = unique(max.x))
  


## plot the accuracy by weight of fish
ggplot(models_accuracy_by_N %>%
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)) %>%
         mutate(weight_group = ifelse(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600, "400 - 600", "900-1100")) %>%
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         filter(N_fish >= 5) %>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(weight_group, predicted_value, color = response)) + 
  geom_boxplot() +
  #geom_smooth() + 
  geom_hline(yintercept = 0, color = "red") +
  geom_text(data = wilcox.sig, aes(label = sig.result, y = max.x, color = response), show.legend = FALSE, size =5)+
  ylab("Residual") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response, scales = "free") + 
  theme_minimal()+
  scale_color_manual(values = cust_cols)
```


Residuals of testing data for high-N (at least 5 fish) sampling events showed that for all approaches, the median value of [Hg] residuals for fish in the range of the standardized weights of interest (500 g and 1000 g) generally trended towards zero, though had some small but significant (p < 0.05) differences from medians For Walleye models, for most approaches, for Northern Pike 400-600 g LMER, bootstrapped LMER and INLA approaches. While medians of [As] values for all approaches visually deviated from zero none of these deviations were significant. The outliers in these data indicated a potential bias for overestimation of some values in the RSTAN and INLA approaches, while more of the outliers for the SER, LMER and bootstrapped LMER approaches were underestimated (Fig \@ref(fig:resids-fishsize)). Bootstrapped LMER showed little difference from LMER values.


```{r resids-small-eventsize, fig.height = 8, fig.cap = "Residuals for fish from events modelled with less than five fish, within 100 g of the targeted prediction weights (500g and 1000g) from each modelling approach in the study. Values are displayed in boxplots where the edges of the box represent the 25th and 75th percentiles and the central line the median, with the whiskers extending out to 1.5 x the interquartile range. A red horizontal line on each plot indicates where there is a residual of zero. '*' are used to represent medians that significnatly deviate from zero based on two sided wilcoxon tests."}
wilcox.sig <- models_accuracy_by_N %>%
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)) %>%
         mutate(weight_group = ifelse(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600, "400 - 600", "900-1100")) %>%
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         filter(N_fish < 5) %>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))) %>%
  group_by(CONTAMINANT) %>%
  mutate(max.x = max(predicted_value)*1.15) %>%
  group_by(weight_group, response, CONTAMINANT, SPECIES_NAME) %>%
  summarise(sig.result = ifelse(wilcox.test(predicted_value)$p.value < 0.05, "*", ""), 
            max.x = unique(max.x))

## plot the accuracy by weight of fish
ggplot(models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)) %>% 
         filter(N_fish < 5) %>% mutate(weight_group = ifelse(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600, "400 - 600", "900-1100")) %>% 
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(weight_group, predicted_value, color = response)) + 
 geom_boxplot() +
  #geom_smooth() + 
  geom_hline(yintercept = 0, color = "red") +
  geom_text(data = wilcox.sig, aes(label = sig.result, y = max.x, color = response), show.legend = FALSE, size =5)+
  ylab("Residual") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response, scales = "free") + 
  theme_minimal() + 
  ggtitle("Residuals for small n lakes (4 or fewer)")+
  scale_color_manual(values = cust_cols)
```


When only the small-N sampling events (4 or less fish) were investigated, no significant (p < 0.05) differences from zero were present, and there was visual overlap of medians and the zero line, indicating that the LMER, bootstrapped LMER, RSTAN and INLA approaches were estimating contaminant values for those lakes as effectively as the lakes that could be modelled using SER (Fig \@ref(fig:resids-small-eventsize)). 


```{r resids-percent, include = F}
## plot the accuracy by the amount of contaminant being predicted
ggplot(models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)|(WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)) %>% filter(N_fish < 10) %>% 
         mutate(weight_group = ifelse(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600, "400 - 600", "900-1100")) %>%
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(VALUE, predicted_value, color = response, shape = weight_group)) + 
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = c(0.1, -0.1), color = "red") +
  ylab("Residual") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response, scales = "free") + 
  theme_minimal() + 
  ggtitle("Residuals for small n lakes (4 or fewer)")+
  scale_color_manual(values = cust_cols)
```


```{r resids-percent-1000g, fig.width=8, fig.height=10, fig.cap = "Predicted concentration of [As] and [Hg] in fish tissue of 400-600g and 900-1100g fish compared to known values. Points display each individual fish prediction and a solid red line shows a 1-1 relationship. Dashed red lines provide an interval for predicted values that are within 25% of the measured value. A general lm model is also displayed with the R2 of the relationship models, for the sets that had enough data to do so."}
## Lm summaries
lm_sums <- models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)|(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)) %>% 
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))) %>%
  mutate(predicted = VALUE + predicted_value) %>%
  group_by(CONTAMINANT) %>%
  mutate(text.x = max(VALUE)* 0.3, text.y = max(predicted)*0.85) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$response)) %>%
    map(~ list(mod = lm(predicted~VALUE, data =.x), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(R2 = round(summary(.x$mod)$adj.r.squared, 2), 
                     intercept = round(.x$mod$coef[[1]], 2),
                     slope = round(.x$mod$coef[[2]], 2),
                     p = round(summary(.x$mod)$coef[2,4], 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         response = factor(str_extract(set, "SER|boot_LMER|LMER|RSTAN|INLA"), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")),
         R2.text = paste0("Slope = ", slope, "\nIntercept = ", intercept  ,"\nR2 = ",R2))

## plot the accuracy by the amount of contaminant being predicted
plot1 <- ggplot(models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)|(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)) %>% 
         filter(CONTAMINANT=="As") %>% 
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(VALUE, (predicted_value+VALUE), color = response)) + 
  geom_point(alpha=0.25) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept, color = response), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  ylab("predicted concentration (ug/g wet weight)") + xlab ("actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response) + 
  theme_minimal() + 
  scale_color_manual(values = cust_cols)

plot2 <- ggplot(models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 900 & WEIGHT_GRAM <= 1100)|(WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)) %>% 
         filter(CONTAMINANT=="Hg") %>% 
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(VALUE, (predicted_value+VALUE), color = response)) + 
  geom_point(alpha=0.25) +
  #geom_smooth()+
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept, color = response), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  ylab("predicted concentration (ug/g wet weight)") + xlab ("actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response) + 
  theme_minimal() + 
  scale_color_manual(values = cust_cols)

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```

Each modelling approach resulted in different error distributions, with all approaches estimating test data values with averaged accuracy for [As] fallig close to to 25% accuracy at most concentrations, and good accuracy (average estimated prediction within 25% accuracy) for [Hg] models up to a concentration of approximately 1.25 ug/g~wet\ weight~. There were biases in observed error that appeared to be driven by test values higher than 1.25 ug/g~wet\ weight~, with SER, LMER and bootstrapped LMER values resulting in underestimated predictions, and RSTAN and INLA resulting in overestimated values (Fig \@ref(fig:resids-percent-1000g)). 


```{r resids-percent-500g, include =FALSE}
## plot the accuracy by the amount of contaminant being predicted
ggplot(models_accuracy_by_N %>% 
         filter((WEIGHT_GRAM >= 400 & WEIGHT_GRAM <= 600)) %>%
         #filter(N_fish < 5) %>% 
         filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "INLA_resid", "RSTAN_resid"))%>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA"))), aes(round(VALUE, 1), (predicted_value+VALUE)/VALUE, color = response, group = as.factor(round(VALUE, 1)))) + 
  geom_boxplot() +
  geom_hline(yintercept = 1, color = "red") +
  ylab("Accuracy (predicted/actual)") + xlab ("actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~response, scales = "free") + 
  theme_minimal() + 
  ggtitle("Residuals for 400 - 600g fish")+
  scale_color_manual(values = cust_cols)

```


## Relative computational requirements
```{r RMSEvsTime, fig.cap="Global RMSE for each modelling approach compared to the computation time required to perform it. The time in seconds, is presented on a log-scaled axis."}
## Calculate overall RMSE of each model, and total time to run model (Models are at level of each SPECIES_NAME - CONTAMINANT combination)
models_overallRMSE <- models_accuracy_by_N %>% 
  filter(response %in% c("LMER_resid", "boot_resid", "SER_residuals", "RSTAN_resid", "INLA_resid")) %>% 
  group_by(SPECIES_NAME, CONTAMINANT, response) %>% 
  summarize(rmse = sqrt(mean(predicted_value^2))) %>% 
         mutate(response = factor(gsub("_resid|_residuals", "", gsub("boot", "boot_LMER", response)), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")))
### Compile times into one dataframe
model_times <- rbind(SER_times, LMER_times %>% mutate(method = gsub("Boot.", "boot_", method)), RSTAN_times, INLA_times) %>% 
  left_join(models_overallRMSE, by = c("SPECIES_NAME", "CONTAMINANT", "method" = "response"))%>% 
         mutate(method = factor(method, levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")))

## plot the model accuracies vs the time required to run each model
# indicate the n used for each model as well
ggplot(model_times, aes(run.time, rmse, color = method, shape = method)) +
  geom_point() + 
  facet_grid(CONTAMINANT~SPECIES_NAME, scales = "free")+ scale_x_log10() + theme_minimal()+
  scale_color_manual(values = cust_cols) + 
  xlab("Processing time (seconds)") + ylab(expression("RMSE"[global]))
```


Generally, the LMER, RSTAN and INLA models had lower global RMSE and better model fit than the SER approach, with the exception of the [As] Lake trout model, which had the lowest sample size of all models in this study. While SER was generally the quickest of all modelling approaches for [As] datasets, INLA had comparable speeds in the larger [Hg] datasets. LMER and LMER bootstrapping had variable global RMSE, but they were generally not the lowest RMSE for any modelling set, aside from the [Hg] Lake Trout model, where they performed comparatively with the INLA model. LMER approaches were more time intensive than either INLA or SER, and bootstrapping did not reliably reduce RMSE. RSTAN also had variable performance in terms of global RMSE and took the most computational time of any approach, though it generally had lower error compared to SER, it resulted in higher error compared to the LMER models in the [Hg] Lake Trout dataset and [As] Northern Pike and Walleye datasets, and the SER approach in the [As] Lake Trout dataset. The INLA models had the lowest computational times and RMSE relative to all other models, with the exception of the [As] Lake Trout dataset (Fig \@ref(fig:RMSEvsTime)).


# Discussion


The Bayesian approaches resulted in the most comparable predictions to the SER approach, with the added benefit of adding predictions for low sample number lake sampling events (less than 5 fish) that were comparable to the accuracy of predictions from higher sample number lake sampling events (5 fish or more). The LMER approach had more noise in the relationship with SER predictions, demonstrated by lower R2 fits of the relationship between values predicted by the two methods. LMER, bootstrapped LMER, RSTAN and INLA approaches had an approximately linear relationship with SER predictions. It is likely that there was more error for higher values of contaminant in the dataset, as these values were underrepresented in the data used for training these models compared to lower levels of contamination. This seems to be a naturally occurring characteristic of the dataset (there are simply not as many lakes and fish with high levels of contaminant) it will continue to be a challenge for accurate standardization of values for higher contaminant levels, and introduces some bias into the models. In freshwater systems, [Hg] typically ranges from .... for Lake Trout, ... for Northern Pike and ... for Walleye, which align quite well with the range we observed in the data .... for Lake Trout, ... for Northern Pike and ... for Walleye. The higher variance in response due to LMER approaches is likely due to the limited capability for this approach to account for uncertainty in random effects, and it appears that our bootstrapping implementation did little to correct for this issue.   

While the accuracy was not consistent across the contaminant gradient, Bayesian approaches were able to predict [As] and [Hg] concentrations in fish tissue to comaparable levels of the SER and lmer approaches, and achieve this level of accuracy in lakes sampling events with less than 5 fish across all three fish types. We conclude INLA and RSTAN can standardize contaminant concentrations from events with less than 5 fish to our 500g and 1000g targets as effectively as higher-saple number events in the SER approach. As expected, all models performed better for sampling events with more fish, and the biases in estimation that appeared in the different datasets correlated with differences in representation of values in the underlying dataset. Future work will aim to determine whether Bayesian models with multiple fish species in the same model can overcome some of the limitations related to bias in the distribution on contaminant concentration, or whether differences in lifestyle and ecology introduce more noise and reduce predictive accuracy.

While both Bayesian approaches performed comparably for most metrics, INLA models were much less computationally intensive and had improved RMSE~global~ compared to the RSTAN implementation. As these approaches were comparable in terms of difficulty of implementation, and the accuracy of the INLA approach is improved, we suggest that INLA is a viable alternative to standardizing values via the SER approach, that may allow for incorporation of more data into analyses. 

Each had different benefits and drawbacks in terms of implementation. Conceptually, the SER approach is the most simple to understand, given that is essentially a group of independent linear models. This can also mean there is more manual intervention required, as error is not 'averaged out' over the dataset. The LMER, STAN and INLA are all more conceptually challenging, however, there is quite a jump in the complexity of a Bayesian model from the LMER approach. Comparatively, understanding of the Bayesian (RSTAN), and the approximated Bayesian (INLA) approach are again more complex, which should be considered when model tuning is required, which based on this study, would likely be required for smaller datasets (<300). 

The different approaches resulted in different biases in predictions. While SER and LMER approaches were more likely to underestimate high values, based on results from testing data, the Bayesian approaches appeared to be more likely to overestimate high values. This conflicted with the comparison of predicted results, but this was likely a result of higher error associated with SER and LMER estimates, which was demonstrated with the lower R2 of these models than the RSTAN and INLA approaches. All approaches had similar losses in accuracy as the amount of contaminant increased, due to underepresentation of high contaminant values in the underlying dataset. The tendency of the INLA approach to overestimate values may be a more desirable manifestation of estimation error for developing fish consumption guidelines and protection of fish stocks, but may be result in overly cautious prescriptions. 

Results of the modelling approaches does not suggest that the different lifestyles of the assessed fish species influence the performance of the model, so this approach is likely to be suitable for many types of fishes. 


# Conclusion




<!---
# Supplemental Tables

```{r model-estimates}
## This chunk creates a table output of the model estimates from each approach. 

```
--->

# Supplemental Figures
```{r response-values, fig.height=10, fig.cap = "Number of fish with different contaminant concentrations"}
ggplot(all_contaminants, aes(VALUE, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  facet_wrap(CONTAMINANT~., scales = "free") + 
  theme_minimal() + xlab("ug/g wet weight")
```

```{r weight-values, fig.height=10, fig.cap = "Number of fish with different contaminant concentrations. Vertical black lines show the weights that are commonly used for standardization."}
ggplot(all_contaminants, aes(WEIGHT_GRAM, color = SPECIES_NAME)) + 
  geom_density(aes(y = after_stat(count)), position = "identity", fill = NA) + 
  facet_wrap(CONTAMINANT~., scales = "free") + 
  theme_minimal() + xlab("wet weight (g)")+
  geom_vline(xintercept = c(500, 1000))
```


```{r pred-500g, fig.cap = "Predicted concentration of [As] and [Hg] in fish tissue of 500g fish compared to values predicted through the SER approach. Points display each individual fish prediction and a solid red line shows a 1-1 relationship. Dashed red lines provide an interval for predicted values that are within 25% of the predicted SER value. A general loess model is also displayed for [Hg] models to better represent overall trends."}

## Lm summaries
lm_sums <- pred.plot %>% filter(WEIGHT_GRAM == 500) %>% 
  group_by(CONTAMINANT) %>%
  mutate(text.x = max(SER)* 0.3, text.y = max(pred.fit, na.rm = T)*0.85) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$method)) %>%
    map(~ list(mod = lm(pred.fit~SER, data =.x), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(R2 = round(summary(.x$mod)$adj.r.squared, 2), 
                     intercept = round(.x$mod$coef[[1]], 2),
                     slope = round(.x$mod$coef[[2]], 2),
                     p = round(summary(.x$mod)$coef[2,4], 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         method = factor(str_extract(set, "SER|boot_LMER|LMER|RSTAN|INLA"), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")),
         R2.text = paste0("Slope = ", slope, "\nIntercept = ", intercept  ,"\nR2 = ",R2))

## plots for each size prediction  
plot1 <- ggplot(pred.plot %>% filter(CONTAMINANT == "As" & WEIGHT_GRAM == 500), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  ylab("predicted concentration (ug/g wet weight)") + xlab ("actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~method, scales = "free")+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

plot2 <- ggplot(pred.plot %>% filter(CONTAMINANT == "Hg"& WEIGHT_GRAM == 500), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  ylab("predicted concentration (ug/g wet weight)") + xlab ("actual concentration (ug/g wet weight)") +
  facet_grid(CONTAMINANT+SPECIES_NAME~method, scales = "free")+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```

```{r pred-1000g, fig.cap = "Predicted concentration of [As] and [Hg] in fish tissue of 1000g fish compared to values predicted through the SER approach. Points display each individual fish prediction and a solid red line shows a 1-1 relationship. Dashed red lines provide an interval for predicted values that are within 25% of the predicted SER value. A general loess model is also displayed for [Hg] models to better represent overall trends."}

## Lm summaries
lm_sums <- pred.plot %>% filter(WEIGHT_GRAM == 1000) %>% 
  group_by(CONTAMINANT) %>%
  mutate(text.x = max(SER)* 0.3, text.y = max(pred.fit, na.rm = T)*0.85) %>%
  group_by() %>%
  split(list(.$CONTAMINANT, .$SPECIES_NAME, .$method)) %>%
    map(~ list(mod = lm(pred.fit~SER, data =.x), 
               text.x = unique(.x$text.x), 
               text.y = unique(.x$text.y))) %>%
    map(~ data.frame(R2 = round(summary(.x$mod)$adj.r.squared, 2), 
                     intercept = round(.x$mod$coef[[1]], 2),
                     slope = round(.x$mod$coef[[2]], 2),
                     p = round(summary(.x$mod)$coef[2,4], 2),
                     text.x = .x$text.x, 
                     text.y = .x$text.y)) %>%
  bind_rows(.id = "set") %>%
  mutate(CONTAMINANT = str_extract(set, "^Hg|^As"), 
         SPECIES_NAME = str_extract(set, "Lake Trout|Walleye|Northern Pike"),
         method = factor(str_extract(set, "SER|boot_LMER|LMER|RSTAN|INLA"), levels = c("SER", "LMER", "boot_LMER", "RSTAN", "INLA")),
         R2.text = paste0("Slope = ", slope, "\nIntercept = ", intercept  ,"\nR2 = ",R2))

## plots for each size prediction  
plot1 <- ggplot(pred.plot %>% filter(CONTAMINANT == "As" & WEIGHT_GRAM == 1000), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="As"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  facet_grid(CONTAMINANT+SPECIES_NAME~method, scales = "free")+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

plot2 <- ggplot(pred.plot %>% filter(CONTAMINANT == "Hg"& WEIGHT_GRAM == 1000), aes(SER, pred.fit, color = method))+ 
  geom_point(alpha = 0.25)+ 
    geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept), col = "white", linewidth = 1.5) +
  geom_abline(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(slope = slope, intercept = intercept, color = method), linewidth = 1) +
  geom_abline(slope = 1, color = "red") +
  geom_abline(slope = 1.25, color = "red", lty = 2) +
  geom_abline(slope = 0.75, color = "red", lty = 2) +
  geom_text(data = lm_sums%>% 
         filter(CONTAMINANT=="Hg"), aes(label = R2.text, x = text.x, y = text.y), size = 3, show.legend = F)+
  facet_grid(CONTAMINANT+SPECIES_NAME~method, scales = "free")+
  theme_minimal()+
  scale_color_manual(values = cust_cols)+ 
  ylab("predicted concentration (ug/g wet weight)") + xlab ("SER predicted concentration (ug/g wet weight)") 

ggarrange(plot1, plot2, ncol =1, common.legend = T)
```


# References

